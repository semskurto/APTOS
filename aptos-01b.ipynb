{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Repository source: https://github.com/qubvel/efficientnet\n",
    "sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n",
    "from efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                        ModelCheckpoint, CSVLogger)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Files and file sizes\n",
      "train.csv                     | 0.05 MB\n",
      "sample_submission.csv         | 0.03 MB\n",
      "test.csv                      | 0.03 MB\n",
      "train_images                  | 0.14 MB\n",
      "test_images                   | 0.07 MB\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import relu, elu, hard_sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5-C.h5'\n",
    "\n",
    "# Set seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# For keeping time. GPU limit for this competition is set to Â± 9 hours.\n",
    "t_start = time.time()\n",
    "\n",
    "# File sizes and specifications\n",
    "print('\\n# Files and file sizes')\n",
    "for file in os.listdir(KAGGLE_DIR):\n",
    "    print('{}| {} MB'.format(file.ljust(30), \n",
    "                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet-keras-weights-b0b5',\n",
       " 'aptos2019-blindness-detection',\n",
       " 'diabetic-retinopathy-resized-train-15-19-dg',\n",
       " 'efficientnet',\n",
       " 'aptos-00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-A)\n",
      "Training images: 3662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              1\n",
       "3  002c21358ce6          0  002c21358ce6.png              0\n",
       "4  005b95c28852          0  005b95c28852.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-B)\n",
      "Training images: 1857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              0\n",
       "3  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "4  00a8624548a9          2  00a8624548a9.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-C)\n",
      "Training images: 1487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "      <td>00b74780d31d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              0\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "3  00a8624548a9          2  00a8624548a9.png              0\n",
       "4  00b74780d31d          2  00b74780d31d.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-D)\n",
      "Training images: 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104b032c141</td>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0243404e8a00</td>\n",
       "      <td>4</td>\n",
       "      <td>0243404e8a00.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02685f13cefd</td>\n",
       "      <td>4</td>\n",
       "      <td>02685f13cefd.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  001639a390f0          4  001639a390f0.png              1\n",
       "1  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "2  0104b032c141          3  0104b032c141.png              0\n",
       "3  0243404e8a00          4  0243404e8a00.png              1\n",
       "4  02685f13cefd          4  02685f13cefd.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path specifications\n",
    "TRAIN_DF_A_PATH = \"../input/aptos-00/df_train_A.csv\"\n",
    "TRAIN_DF_B_PATH = \"../input/aptos-00/df_train_B.csv\"\n",
    "TRAIN_DF_C_PATH = \"../input/aptos-00/df_train_C.csv\"\n",
    "TRAIN_DF_D_PATH = \"../input/aptos-00/df_train_D.csv\"\n",
    "\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-A)\")\n",
    "train_df_A = pd.read_csv(TRAIN_DF_A_PATH)\n",
    "print(f\"Training images: {train_df_A.shape[0]}\")\n",
    "display(train_df_A.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-B)\")\n",
    "train_df_B = pd.read_csv(TRAIN_DF_B_PATH)\n",
    "print(f\"Training images: {train_df_B.shape[0]}\")\n",
    "display(train_df_B.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-C)\")\n",
    "train_df_C = pd.read_csv(TRAIN_DF_C_PATH)\n",
    "print(f\"Training images: {train_df_C.shape[0]}\")\n",
    "display(train_df_C.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-D)\")\n",
    "train_df_D = pd.read_csv(TRAIN_DF_D_PATH)\n",
    "print(f\"Training images: {train_df_D.shape[0]}\")\n",
    "display(train_df_D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_B\n",
    "df0 = df.iloc[:0,:]\n",
    "df1 = df.iloc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainLabels15.csv',\n",
       " 'trainLabels19.csv',\n",
       " 'DGTraining.csv',\n",
       " 'testLabels15.csv',\n",
       " 'DGTesting.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels15.csv')\n",
    "df_x19 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x19['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x15['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = df_x15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_x15 = df_x15[df_x15['diagnosis'] == 1]\n",
    "df_2_x15 = df_x15[df_x15['diagnosis'] == 2]\n",
    "df_3_x15 = df_x15[df_x15['diagnosis'] == 3]\n",
    "df_4_x15 = df_x15[df_x15['diagnosis'] == 4]\n",
    "\n",
    "df_1_x19 = df_x19[df_x19['diagnosis'] == 1]\n",
    "df_2_x19 = df_x19[df_x19['diagnosis'] == 2]\n",
    "df_3_x19 = df_x19[df_x19['diagnosis'] == 3]\n",
    "df_4_x19 = df_x19[df_x19['diagnosis'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_x15['binary_target'] = 0\n",
    "df_2_x15['binary_target'] = 1\n",
    "df_3_x15['binary_target'] = 1\n",
    "df_4_x15['binary_target'] = 1\n",
    "\n",
    "df_1_x19['binary_target'] = 0\n",
    "df_2_x19['binary_target'] = 1\n",
    "df_3_x19['binary_target'] = 1\n",
    "df_4_x19['binary_target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1_x15, df_2_x15,df_3_x15, df_4_x15, df_1_x19, df_2_x19, df_3_x19, df_4_x19], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file_name column to df_train and df_test\n",
    "\n",
    "def create_fname(x):\n",
    "    \n",
    "    fname = str(x) + '.jpg'\n",
    "    \n",
    "    return fname\n",
    "\n",
    "df['file_name'] = df['id_code'].apply(create_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8360\n",
       "0    2813\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "\n",
    "df['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11173, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>a5a2a7003d60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a5a2a7003d60.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>9384_left</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9384_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>40049_right</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40049_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>24163_left</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24163_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>25401_left</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25401_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis  binary_target         file_name\n",
       "2691  a5a2a7003d60          1              0  a5a2a7003d60.jpg\n",
       "3967     9384_left          2              1     9384_left.jpg\n",
       "7628   40049_right          2              1   40049_right.jpg\n",
       "9365    24163_left          4              1    24163_left.jpg\n",
       "5913    25401_left          2              1    25401_left.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df[df['binary_target'] == 0]\n",
    "df_1 = df[df['binary_target'] == 1]\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8360\n",
       "0    2813\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new target distribution\n",
    "\n",
    "df_data['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10055, 4)\n",
      "(1118, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_data, test_size=0.1, random_state=11)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7526\n",
       "0    2529\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_train['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    834\n",
       "0    284\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_val['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create sub folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "# val_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "a_0 = os.path.join(train_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(train_dir, 'b_1')\n",
    "os.mkdir(b_1)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "a_0 = os.path.join(val_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(val_dir, 'b_1')\n",
    "os.mkdir(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_dir', 'val_dir']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the folders exist\n",
    "os.listdir('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>9717_right</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9717_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>17899_left</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17899_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>16963_left</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16963_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>3993_right</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3993_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>19158_left</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19158_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_code  diagnosis  binary_target       file_name\n",
       "4004  9717_right          2              1  9717_right.jpg\n",
       "8443  17899_left          3              1  17899_left.jpg\n",
       "4913  16963_left          2              1  16963_left.jpg\n",
       "9039  3993_right          4              1  3993_right.jpg\n",
       "1098  19158_left          1              0  19158_left.jpg"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file_name as the index in df_data\n",
    "df_data.set_index('file_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'train_images',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/aptos2019-blindness-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['file_name'])\n",
    "\n",
    "# ============================\n",
    "# Transfer the train images\n",
    "# ============================\n",
    "\n",
    "for fname in train_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "# ============================\n",
    "# Transfer the val images\n",
    "# ============================\n",
    "\n",
    "# Get a list of train and val images\n",
    "val_list = list(df_val['file_name'])\n",
    "\n",
    "for fname in val_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529\n",
      "7526\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the train sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n",
      "834\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the val sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (456, 456))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10055 images belonging to 2 classes.\n",
      "Found 1118 images belonging to 2 classes.\n",
      "Found 1118 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "val_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "# Get the number of train and val steps\n",
    "train_steps = np.ceil(num_train_samples // train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples // val_batch_size)\n",
    "# Pre-process the input images in the same way as the ImageNet images \n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= preprocess_image,\n",
    "    rescale=1 / 255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "# We are only going to use this to make a prediction on the val set. That's\n",
    "# why the path is set as val_path\n",
    "test_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=4,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in EfficientNetB5\n",
    "effnet = EfficientNetB5(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "effnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all Batch Normalization layers by Group Normalization layers\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=4, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 28,172,146\n",
      "Trainable params: 28,172,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.1))\n",
    "    #model.add(Dense(5, activation=sigmoid))\n",
    "    model.add(Dense(2, activation=\"hard_sigmoid\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_0': 0, 'b_1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # Class 0\n",
    "    1: 1.0, # Class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "1256/1256 [==============================] - 1255s 999ms/step - loss: 0.5648 - categorical_accuracy: 0.7370 - val_loss: 0.5227 - val_categorical_accuracy: 0.7500\n",
      "Epoch 2/17\n",
      "1256/1256 [==============================] - 1221s 972ms/step - loss: 0.5054 - categorical_accuracy: 0.7547 - val_loss: 0.4986 - val_categorical_accuracy: 0.7568\n",
      "Epoch 3/17\n",
      "1256/1256 [==============================] - 1226s 976ms/step - loss: 0.4893 - categorical_accuracy: 0.7700 - val_loss: 0.5225 - val_categorical_accuracy: 0.7640\n",
      "Epoch 4/17\n",
      "1256/1256 [==============================] - 1223s 974ms/step - loss: 0.4841 - categorical_accuracy: 0.7767 - val_loss: 0.4970 - val_categorical_accuracy: 0.7703\n",
      "Epoch 5/17\n",
      " 317/1256 [======>.......................] - ETA: 14:43 - loss: 0.4432 - categorical_accuracy: 0.7874"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_categorical_accuracy\", \n",
    "                      mode=\"max\", \n",
    "                      patience=12)\n",
    "\n",
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr, early_stopper, csv_logger]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_gen.samples // train_batch_size, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=17, verbose=1,\n",
    "                   callbacks=[reduce_lr, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.830397</td>\n",
       "      <td>0.371946</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.802703</td>\n",
       "      <td>0.588299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  categorical_accuracy      loss        lr  val_categorical_accuracy  \\\n",
       "15     15              0.830397  0.371946  0.000005                  0.802703   \n",
       "\n",
       "    val_loss  \n",
       "15  0.588299  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training log\n",
    "df = pd.read_csv('training_log.csv')\n",
    "\n",
    "# we are monitoring val_loss\n",
    "best_acc = df['val_categorical_accuracy'].max()\n",
    "\n",
    "# display the row with the best accuracy\n",
    "df[df['val_categorical_accuracy'] == best_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.5796791804593562\n",
      "val_categorical_accuracy: 0.7966405375139978\n"
     ]
    }
   ],
   "source": [
    "# Here the best epoch will be used.\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_categorical_accuracy = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_categorical_accuracy:', val_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
