{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Repository source: https://github.com/qubvel/efficientnet\n",
    "sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n",
    "from efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                        ModelCheckpoint, CSVLogger)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Files and file sizes\n",
      "train.csv                     | 0.05 MB\n",
      "sample_submission.csv         | 0.03 MB\n",
      "test.csv                      | 0.03 MB\n",
      "train_images                  | 0.14 MB\n",
      "test_images                   | 0.07 MB\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import relu, elu, sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5-C.h5'\n",
    "\n",
    "# Set seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# For keeping time. GPU limit for this competition is set to Â± 9 hours.\n",
    "t_start = time.time()\n",
    "\n",
    "# File sizes and specifications\n",
    "print('\\n# Files and file sizes')\n",
    "for file in os.listdir(KAGGLE_DIR):\n",
    "    print('{}| {} MB'.format(file.ljust(30), \n",
    "                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet-keras-weights-b0b5',\n",
       " 'aptos2019-blindness-detection',\n",
       " 'diabetic-retinopathy-resized-train-15-19-dg',\n",
       " 'efficientnet',\n",
       " 'aptos-00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-A)\n",
      "Training images: 3662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              1\n",
       "3  002c21358ce6          0  002c21358ce6.png              0\n",
       "4  005b95c28852          0  005b95c28852.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-B)\n",
      "Training images: 1857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              0\n",
       "3  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "4  00a8624548a9          2  00a8624548a9.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-C)\n",
      "Training images: 1487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "      <td>00b74780d31d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              0\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "3  00a8624548a9          2  00a8624548a9.png              0\n",
       "4  00b74780d31d          2  00b74780d31d.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-D)\n",
      "Training images: 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104b032c141</td>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0243404e8a00</td>\n",
       "      <td>4</td>\n",
       "      <td>0243404e8a00.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02685f13cefd</td>\n",
       "      <td>4</td>\n",
       "      <td>02685f13cefd.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  001639a390f0          4  001639a390f0.png              1\n",
       "1  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "2  0104b032c141          3  0104b032c141.png              0\n",
       "3  0243404e8a00          4  0243404e8a00.png              1\n",
       "4  02685f13cefd          4  02685f13cefd.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path specifications\n",
    "TRAIN_DF_A_PATH = \"../input/aptos-00/df_train_A.csv\"\n",
    "TRAIN_DF_B_PATH = \"../input/aptos-00/df_train_B.csv\"\n",
    "TRAIN_DF_C_PATH = \"../input/aptos-00/df_train_C.csv\"\n",
    "TRAIN_DF_D_PATH = \"../input/aptos-00/df_train_D.csv\"\n",
    "\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-A)\")\n",
    "train_df_A = pd.read_csv(TRAIN_DF_A_PATH)\n",
    "print(f\"Training images: {train_df_A.shape[0]}\")\n",
    "display(train_df_A.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-B)\")\n",
    "train_df_B = pd.read_csv(TRAIN_DF_B_PATH)\n",
    "print(f\"Training images: {train_df_B.shape[0]}\")\n",
    "display(train_df_B.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-C)\")\n",
    "train_df_C = pd.read_csv(TRAIN_DF_C_PATH)\n",
    "print(f\"Training images: {train_df_C.shape[0]}\")\n",
    "display(train_df_C.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-D)\")\n",
    "train_df_D = pd.read_csv(TRAIN_DF_D_PATH)\n",
    "print(f\"Training images: {train_df_D.shape[0]}\")\n",
    "display(train_df_D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_C\n",
    "df0 = df.iloc[:0,:]\n",
    "df1 = df.iloc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainLabels15.csv',\n",
       " 'trainLabels19.csv',\n",
       " 'DGTraining.csv',\n",
       " 'testLabels15.csv',\n",
       " 'DGTesting.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels15.csv')\n",
    "df_x19 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x19['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x15['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = df_x15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_x15 = df_x15[df_x15['diagnosis'] == 2]\n",
    "df_3_x15 = df_x15[df_x15['diagnosis'] == 3]\n",
    "df_4_x15 = df_x15[df_x15['diagnosis'] == 4]\n",
    "\n",
    "df_2_x19 = df_x19[df_x19['diagnosis'] == 2]\n",
    "df_3_x19 = df_x19[df_x19['diagnosis'] == 3]\n",
    "df_4_x19 = df_x19[df_x19['diagnosis'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_x15['binary_target'] = 0\n",
    "df_3_x15['binary_target'] = 1\n",
    "df_4_x15['binary_target'] = 1\n",
    "\n",
    "df_2_x19['binary_target'] = 0\n",
    "df_3_x19['binary_target'] = 1\n",
    "df_4_x19['binary_target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2_x15, df_3_x15, df_4_x15, df_2_x19, df_3_x19, df_4_x19], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file_name column to df_train and df_test\n",
    "\n",
    "def create_fname(x):\n",
    "    \n",
    "    fname = str(x) + '.jpg'\n",
    "    \n",
    "    return fname\n",
    "\n",
    "df['file_name'] = df['id_code'].apply(create_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6291\n",
       "1    2069\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "\n",
    "df['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8360, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>962cf85e4f6d</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>962cf85e4f6d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>43816_right</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43816_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>8515_left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8515_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>36636_left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36636_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>42510_left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42510_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis  binary_target         file_name\n",
       "5882  962cf85e4f6d          2              0  962cf85e4f6d.jpg\n",
       "5234   43816_right          2              0   43816_right.jpg\n",
       "1058     8515_left          2              0     8515_left.jpg\n",
       "4408    36636_left          2              0    36636_left.jpg\n",
       "5077    42510_left          2              0    42510_left.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df[df['binary_target'] == 0]\n",
    "df_1 = df[df['binary_target'] == 1]\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6291\n",
       "1    2069\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new target distribution\n",
    "\n",
    "df_data['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7524, 4)\n",
      "(836, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_data, test_size=0.1, random_state=11)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5672\n",
       "1    1852\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_train['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    619\n",
       "1    217\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_val['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create sub folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "# val_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "a_0 = os.path.join(train_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(train_dir, 'b_1')\n",
    "os.mkdir(b_1)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "a_0 = os.path.join(val_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(val_dir, 'b_1')\n",
    "os.mkdir(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_dir', 'val_dir']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the folders exist\n",
    "os.listdir('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>41692_right</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41692_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>17481_right</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17481_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>38186_left</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38186_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>14688_left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14688_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>26758_left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26758_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code  diagnosis  binary_target        file_name\n",
       "5004  41692_right          2              0  41692_right.jpg\n",
       "6622  17481_right          3              1  17481_right.jpg\n",
       "7776   38186_left          4              1   38186_left.jpg\n",
       "1833   14688_left          2              0   14688_left.jpg\n",
       "3261   26758_left          2              0   26758_left.jpg"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file_name as the index in df_data\n",
    "df_data.set_index('file_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'train_images',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/aptos2019-blindness-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['file_name'])\n",
    "\n",
    "# ============================\n",
    "# Transfer the train images\n",
    "# ============================\n",
    "\n",
    "for fname in train_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "# ============================\n",
    "# Transfer the val images\n",
    "# ============================\n",
    "\n",
    "# Get a list of train and val images\n",
    "val_list = list(df_val['file_name'])\n",
    "\n",
    "for fname in val_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5672\n",
      "1852\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the train sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the val sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (456, 456))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7524 images belonging to 2 classes.\n",
      "Found 836 images belonging to 2 classes.\n",
      "Found 836 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "val_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "# Get the number of train and val steps\n",
    "train_steps = np.ceil(num_train_samples // train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples // val_batch_size)\n",
    "# Pre-process the input images in the same way as the ImageNet images \n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= preprocess_image,\n",
    "    rescale=1 / 128.)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "# We are only going to use this to make a prediction on the val set. That's\n",
    "# why the path is set as val_path\n",
    "test_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=4,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in EfficientNetB5\n",
    "effnet = EfficientNetB5(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "effnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all Batch Normalization layers by Group Normalization layers\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=4, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 28,172,146\n",
      "Trainable params: 28,172,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(5, activation=sigmoid))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_0': 0, 'b_1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # Class 0\n",
    "    1: 1.0, # Class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "940/940 [==============================] - 932s 991ms/step - loss: 0.5322 - categorical_accuracy: 0.7468 - val_loss: 0.4621 - val_categorical_accuracy: 0.7788\n",
      "Epoch 2/19\n",
      "940/940 [==============================] - 875s 931ms/step - loss: 0.4351 - categorical_accuracy: 0.8031 - val_loss: 0.4230 - val_categorical_accuracy: 0.8056\n",
      "Epoch 3/19\n",
      "940/940 [==============================] - 874s 930ms/step - loss: 0.3976 - categorical_accuracy: 0.8253 - val_loss: 0.3966 - val_categorical_accuracy: 0.8309\n",
      "Epoch 4/19\n",
      "940/940 [==============================] - 875s 930ms/step - loss: 0.3680 - categorical_accuracy: 0.8403 - val_loss: 0.3881 - val_categorical_accuracy: 0.8406\n",
      "Epoch 5/19\n",
      "940/940 [==============================] - 874s 930ms/step - loss: 0.3476 - categorical_accuracy: 0.8493 - val_loss: 0.3846 - val_categorical_accuracy: 0.8442\n",
      "Epoch 6/19\n",
      "640/940 [===================>..........] - ETA: 4:31 - loss: 0.3238 - categorical_accuracy: 0.8645"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_categorical_accuracy\", \n",
    "                      mode=\"max\", \n",
    "                      patience=12)\n",
    "\n",
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr, early_stopper, csv_logger]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_gen.samples // train_batch_size, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=19, verbose=1,\n",
    "                   callbacks=[reduce_lr, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.910591</td>\n",
       "      <td>0.226225</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.406563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  categorical_accuracy      loss        lr  val_categorical_accuracy  \\\n",
       "11     11              0.910591  0.226225  0.000005                  0.858696   \n",
       "\n",
       "    val_loss  \n",
       "11  0.406563  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training log\n",
    "df = pd.read_csv('training_log.csv')\n",
    "\n",
    "# we are monitoring val_loss\n",
    "best_acc = df['val_categorical_accuracy'].max()\n",
    "\n",
    "# display the row with the best accuracy\n",
    "df[df['val_categorical_accuracy'] == best_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4615512432905289\n",
      "val_categorical_accuracy: 0.8441441441441442\n"
     ]
    }
   ],
   "source": [
    "# Here the best epoch will be used.\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_categorical_accuracy = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_categorical_accuracy:', val_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VGX2+PHPIaEYBKkqSwsqi1KSABFxbSjKAuuKXdhgRxTLz9VFRWFXZe0NLFiwFwTRta1lsQAqX1sChC5SBAlBiCA1CCnn98dzJwyTSWaSTDIzyXm/XvPKzL3PvXPuzGTOPOU+V1QVY4wxpl60AzDGGBMbLCEYY4wBLCEYY4zxWEIwxhgDWEIwxhjjsYRgjDEGsIRQ64lIgojsFJEOkSwbTSJyhIhEfLy0iJwqImv8Hi8XkRPCKVuJ53pORG6r7PbGVIfEaAdg9iciO/0eJgF7gCLv8ZWqOqUi+1PVIuDASJetC1S1SyT2IyIjgOGq2s9v3yMise9IEZG7gHaqekm0YzHRYwkhxqhqyRey9wt0hKp+VlZ5EUlU1cKaiM2YaBGRegCqWhztWGozazKKMyJyl4i8ISJTRWQHMFxEjhWRb0Vkq4hsEJHHRKS+Vz5RRFREkr3Hr3nrPxaRHSLyjYh0qmhZb/0gEflRRLaJyOMi8n8ickkZcYcT45UislJEfhORx/y2TRCRCSKyWURWAQPLeX3Gici0gGWTROQR7/4IEVnmHc8q79d7WfvKEZF+3v0kEXnVi20J0DvI86729rtERM7wlvcAngBO8JrjfvV7be/w2/4q79g3i8i7ItImnNcmSMyJIvJP79i2i0iWiPzBW/eEd0zbRSRTRP7kLT8duBnI8GKcW85rW+oY/dZfKSI/eOsXi0iqt7yjd0x5IvKriDzqLb9LRF7y236/pkARmSMi/xaRb4BdQIdQ75+InC0i2d4xrhSRASIyTES+Cyh3i4i8VdbrWGepqt1i9AasAU4NWHYXsBf4Ky6hHwAcDRyDq/EdBvwIXOuVTwQUSPYevwb8CqQD9YE3gNcqUfZgYAcwxFt3I1AAXFLGsYQT43vAQUAysMV37MC1wBKgHdAS+NJ9dIM+z2HATqCx3743Aene4796ZQQ4BdgNpHjrTgXW+O0rB+jn3X8ImA00BzoCSwPKng+08d6Tv3kxHOKtGwHMDojzNeAO7/4AL8Y0oBHwJDAznNcmyPHfCiwAOnuxpAEtvHUXAi28fd4CrAca+n2uXgrxeSzvGIcB63CJUoA/Au2951rsvX6NcZ/X44I9J3CE//sKzMH9DxyF+4wlhnj//gRsBfp7MbYHunjPuRXo7LfvRcCQaP+Px9ot6gHYrZw3p+yEMDPEdqOBN737wb7kn/YrewawuBJlLwO+8lsnwAbKSAhhxtjXb/3bwGjv/pe4pjPfusGUkRC89d8Cf/PuDwJ+LKfsB8A13v3yEsLP/u8FcLV/2SD7XQz8xbsfKiG8DNzjt64prt+oXajXJsjzrvI9b4jXX3AJvZvf5+qlCn4+/Y/xc9/rGFDmBOAXICHIunASwr9CxOD//j0PPFhGuWeBO737abgfOvUrcrx14WZNRvFpnf8DETlSRD4UkV9EZDswHmhVzva/+N3Pp/yO5LLK/sE/DnX/aTll7STMGMN6LmBtOfECvI77xQrul2xJR7yInC4i34nIFhHZivt1Xt5r5dOmvBhE5BIRWeA1iW0Fjgxzv+COr2R/qrod+A1o61cm3PesPS4plCIiN3tNOtu8/TeuQIyhjrGs522PS5xFQdaFI/CzXt77V+ax45Juhnd/OPCGqhZUMqZayxJCfAoccvkM7tfaEaraFPgX7hdgddqA+wULgIgI+3+BBapKjBtw/+w+oYbFvgGcKiLtcE1ar3sxHgC8BdyLa+poBnwSZhy/lBWDiBwGPAWMAlp6+/3Bb7+hhsjm4pqhfPtrgmuaWh9GXIHWAYcHLhSRk3HNeucAzbz97ww3xjCOMejzess7ikhCkHW7cCPpfA4NUsa/TyHU+1dWDKjqHG8fx+F+LLwarFxdZwmhdmgCbAN2ichRwJU18JwfAL1E5K8ikghcD7SuphinA38XkbYi0hLX/l0mVd2Ia254EViuqiu8VQ2BBkAeUOR1pvavQAy3iUgzcedpXOu37kDcF1ceLjeOwP169tkItBOvEz2IqcDlIpIiIg1xX3hfqWqZNa5yPAfcJSKHi5MmIi1wr38hXlMJcAeuhuAfY7KX2IMJdYzPATeLSE/veTuLSHvgG2AzcI+4jvkDvC9lgGzgJBFpLyLNgDEhji3U+/c8MEJEThaReiLSTkT8hw6/iktqu1T12xDPVSdZQqgd/gFcjGsTfgb3C7laeV+6FwCP4P7hDwfm486biHSMT+HaqBcBmbhfiaG8jusTeN0v5q3ADcA7uI7Zc3GJLRy342oqa4CPgVf89rsQeAz43itzJOA/quVTYAWwUUT8m3582/8P14T2jrd9B/Y1b1TUg8C7uNdrOzAZ11H9EfCZF8cab90Gv+3ewH3ZbhGR74PEWO4xqupU4H5vP9tx/RzN1Q2JPh3XMbwO1xdzrrfZ/7xjXuTt9/3yDizU+6eqXwNXeHFuA2axf63uFaA7Vjsok3idLMZUidckkAucq6pfRTseYwKJSGPcaK7uqvpTtOOJRVZDMJUmIgNF5CCvmeOfuCaJUr8ujYkR1wD/Z8mgbHamsqmK43EjeBrgzhM4U1XLajIyJmpEJAd3nsyQaMcSy6zJyBhjDGBNRsYYYzxx1WTUqlUrTU5OjnYYxhgTV+bOnfurqpY3LByIs4SQnJxMVlZWtMMwxpi4IiKhzu4HrMnIGGOMxxKCMcYYwBKCMcYYT1z1IQRTUFBATk4Ov//+e7RDMTWgUaNGtGvXjvr1y5oWyBhTWXGfEHJycmjSpAnJycmUPS+XqQ1Ulc2bN5OTk0OnTp1Cb2CMqZC4bzL6/fffadmypSWDOkBEaNmypdUGTZ0xZQokJ0O9eu7vlCmhtqiauK8hAJYM6hB7r01dMWUKjBwJ+fnu8dq17jFARmXnwg0h7msIxhhTG40duy8Z+OTnu+XVxRJCFW3evJm0tDTS0tI49NBDadu2bcnjvXv3hrWPSy+9lOXLl5dbZtKkSUyp7vpiEKtXr2batGk1/rzG1HU//1yx5ZFQ5xJCpNvkWrZsSXZ2NtnZ2Vx11VXccMMNJY8bNGgAuM7Q4uLiMvfx4osv0qVLlzLXA1xzzTVkVFc9sRyWEIyJjg5lXCi2rOWRUKcSgq9Nbu1aUN3XJlcdP7xXrlxJ9+7dueqqq+jVqxcbNmxg5MiRpKen061bN8aPH19S9vjjjyc7O5vCwkKaNWvGmDFjSE1N5dhjj2XTpk0AjBs3jokTJ5aUHzNmDH369KFLly58/fXXAOzatYtzzjmH1NRUhg0bRnp6OtnZ2aVi++677zj22GNJTU3lmGOOIT8/n1WrVnHCCSfQs2dPevfuzXffuYthjRkzhlmzZpGWlsZjjz223362b9/OKaecQq9evUhJSeGDD/ZdfOzFF18kJSWF1NRULr30UgB++eUXhgwZUrLc9xzGmNLuvhuSkvZflpTkllcbVY2bW+/evTXQ0qVLSy0rS8eOqi4V7H/r2DHsXZTr9ttv1wcffFBVVVesWKEiot9//33J+s2bN6uqakFBgR5//PG6ZMkSVVU97rjjdP78+VpQUKCAfvTRR6qqesMNN+i9996rqqpjx47VCRMmlJS/+eabVVX1vffe0z//+c+qqnrvvffq1Vdfraqq2dnZWq9ePZ0/f/5+Me7evVuTk5N17ty5qqq6detWLSws1F27dunu3btVVXXZsmXap08fVVX99NNPdciQIUGPd+/evbp9+3ZVVd24caMeccQRJc/dpUuXkuP1/T377LP18ccfL3kNtm3bFv6L66ci77mpm157zf1fi7i/r70W7YgqJ1LHAWRpGN+xtWKUUbhquk3u8MMP5+ijjy55PHXqVJ5//nkKCwvJzc1l6dKldO3adb9tDjjgAAYNGgRA7969+eqr4FejPPvss0vKrFmzBoA5c+Zwyy3u+vOpqal069at1HbLli2jQ4cO9OrVC4CDDjoIgD179nDttdeyYMECEhMTWbVqVcjjU1VuueUW5syZQ7169Vi3bh2//vorM2fO5IILLqBFixYAJX9nz55d0vyUmJhI06ZNQz6HMRUVjdE51SUjo2ZjrlNNRjXdJte4ceOS+ytWrODRRx9l5syZLFy4kIEDBwYdT+/rdwBISEigsLAw6L4bNmxYqoyGcbEjVQ06dPPhhx+mffv2LFq0iO+//549e0Jf+OyVV15h27ZtzJs3j+zsbFq1asXvv/9e5nOADRs11S8ao3NqizqVEKLSJufZvn07TZo0oWnTpmzYsIEZM2ZE/DmOP/54pk+fDsCiRYtYunRpqTLdunVj7dq1zJs3rySuoqIitm3bRps2bRARXn755ZLk0qRJE3bs2BH0+bZt28bBBx9MYmIin376KevXrwfg1FNPZdq0aWzZsgWg5O/JJ5/M008/DUBRURHbt2+P4NEb40RjdE4wNX1SWSTUqYSQkQGTJ0PHjiDi/k6eXDNVsl69etG1a1e6d+/OFVdcwXHHHRfx57juuutYv349KSkpPPzww3Tv3r2kScinYcOGTJ06lVGjRpGamsqAAQNKmouee+45+vbty9q1a0tqID179qSoqIjU1NRSncoXXnghX3/9Nenp6bz55pt07twZgJSUFG6++WZOPPFE0tLSuOmmmwB44oknmDFjBj169CA9PZ0ffvgh4q+BMdEYnROoJgewRFQ4HQ2xcqtqp3JtV1BQUNIx/OOPP2pycrIWFBREOarIs/fclOe111STkvYfOJKUVPEO2ap06Fb3AJaKwjqV656dO3fSv39/CgsLUVWeeeYZEhPtLTZ1i6/GP3asaybq0ME1C1ekJaCqHdOx0mxVUaJhdESKyEDgUSABeE5V7wtY3xF4AWgNbAGGq2qOiKQBTwFNgSLgblV9w9vmJeAkYJu3m0tUtfSgeT/p6ekaeAnNZcuWcdRRR4U8BlN72HtuqltysksCgTp2BG9QX7VuH2kiMldV00OVC9mHICIJwCRgENAVGCYiXQOKPQS8oqopwHjgXm95PnCRqnYDBgITRaSZ33Y3qWqadys3GRhjTE2p6i/8aA5gqYpwOpX7ACtVdbWq7gWmAUMCynQFPvfuz/KtV9UfVXWFdz8X2ISrRRhjTMyqasd0NAewVEU4CaEtsM7vcY63zN8C4Bzv/llAExFp6V9ARPoADQD/M57uFpGFIjJBRBoGe3IRGSkiWSKSlZeXF0a4xphoicehlsFE4hd+RoZrHioudn9jPRlAeAkh2JlEgR0Po4GTRGQ+rl9gPVByRpWItAFeBS5VVd8sb7cCRwJHAy2AW4I9uapOVtV0VU1v3doqF8bEqkgNtYyFpBKvv/CrKpyEkAO093vcDsj1L6Cquap6tqr2BMZ6y7YBiEhT4ENgnKp+67fNBm9E1B7gRVzTVNzp169fqZPMJk6cyNVXX13udgceeCAAubm5nHvuuWXuO7ATPdDEiRPJ9zstc/DgwWzdujWc0CPqnnvuqfHnNLElEmcIx9L4/Xj8hV9V4SSETKCziHQSkQbAUOB9/wIi0kpEfPu6FTfiCK/8O7gO5zcDtmnj/RXgTGBxVQ4kWoYNG1Zqeuhp06YxbNiwsLb/wx/+wFtvvVXp5w9MCB999BHNmjUrZ4vqYQnBRGKopU07EV0hE4KqFgLXAjOAZcB0VV0iIuNF5AyvWD9guYj8CBwC+FrazgdOBC4RkWzvluatmyIii4BFQCvgrkgdVE0699xz+eCDD0rm/lmzZg25ubkcf/zxJecF9OrVix49evDee++V2n7NmjV0794dgN27dzN06FBSUlK44IIL2L17d0m5UaNGlUydffvttwPw2GOPkZuby8knn8zJJ58MQHJyMr/++isAjzzyCN27d6d79+4lU2evWbOGo446iiuuuIJu3boxYMCA/Z7HZ+PGjZx11lmkpqaSmppaMsX2mWeeSe/evenWrRuTJ08G3BTZu3fvJi0tLeg1G4LFDpCZmcmf/vQnUlNT6dOnDzt27KCoqIjRo0fTo0cPUlJSePzxxyv4jphoicQZwvE6fr/WCOfstVi5hTpT+frrVU86KbK3668v9ZSlDB48WN99911VdVNQjx49WlX3n+I5Ly9PDz/8cC0uLlZV1caNG6uq6k8//aTdunVTVdWHH35YL730UlVVXbBggSYkJGhmZqaq7ptCurCwUE866SRdsGCBqqp27NhR8/LySmLxPc7KytLu3bvrzp07dceOHdq1a1edN2+e/vTTT5qQkFAyLfZ5552nr776aqljOv/880um2y4sLNStW7fuF0d+fr5269ZNf/311/2OJ5hgse/Zs0c7depUMj34tm3btKCgQJ988kk9++yzS86w9m3rz85Ujk2ROEM41s7wrS0I80zlOjWXUXXxbzbyby5SVW677TZSUlI49dRTWb9+PRs3bixzP19++SXDhw8H3HxAKSkpJeumT59Or1696NmzJ0uWLAk6cZ2/OXPmcNZZZ9G4cWMOPPBAzj777JKptDt16kRamquo+U+f7W/mzJmMGjUKcDOq+uZEeuyxx0hNTaVv376sW7eOFStWhHx9gsW+fPly2rRpUzI9eNOmTUlMTOSzzz7jqquuKjnD2jd1tol9keiIjdfx+7VFrZrXwGsVqXFnnnkmN954I/PmzWP37t0l1xqYMmUKeXl5zJ07l/r165OcnBx0ymt/waaH/umnn3jooYfIzMykefPmXHLJJSH3o+Wcge6buA7cl32wJqNgZs+ezWeffcY333xDUlIS/fr1CxlHWbGrBp8iu6zlJj5Udf7+SEw7YSrPaggRcOCBB9KvXz8uu+yy/TqTfdND169fn1mzZrE22Lnsfk488USmeMMpFi9ezMKFCwE3RXXjxo056KCD2LhxIx9//HHJNmVNT33iiSfy7rvvkp+fz65du3jnnXc44YQTwj6m/v3789RTTwH7pqretm0bzZs3JykpiR9++IFvvy0ZNEb9+vUpKCgotZ+yYj/yyCPJzc0lMzMTgB07dlBYWMiAAQN4+umnS67x4Js629QddXF0T6ywhBAhw4YNY8GCBQwdOrRkWUZGBllZWaSnpzNlyhSOPPLIcvcxatQodu7cSUpKCg888AB9+riRuKmpqfTs2ZNu3bpx2WWX7Td19siRIxk0aFBJp7JPr169uOSSS+jTpw/HHHMMI0aMoGfPnmEfz6OPPsqsWbPo0aMHvXv3ZsmSJQwcOJDCwkJSUlL45z//Sd++ffeLIyUlpVSnclmxN2jQgDfeeIPrrruO1NRUTjvtNH7//XdGjBhBhw4dSq67/Prrr4cdszGmasKa3C5W2OR2Buw9N6aiIja5nTHGmLrBEoIxtUAsTPdg4l+tSAjx1Oxlqsbe69Jq0xxCJrriPiE0atSIzZs32xdFHaCqbN68mUaNGkU7lJhS2+YQMtET953KBQUF5OTkhBwPb2qHRo0a0a5dO+rXrx/tUGJGvXruSzyQiBu6GY5Yu8KXiaxwO5Xj/sS0+vXr06lTp2iHYUzUdOgQ/Mvc5hAyFRX3TUbG1HWRmO4hEhPTmfhnCcGYOGdzCJlIifsmI2OMzSFkIsNqCMZEWawM97Q5hIzVEIyJIt9wT9+wUd9wT7AvZFPzrIZgTBTZJSNNLAkrIYjIQBFZLiIrRWRMkPUdReRzEVkoIrNFpJ3fuotFZIV3u9hveW8RWeTt8zGxSfBNHWTDPU0sCZkQRCQBmAQMAroCw0Ska0Cxh4BXVDUFGA/c623bArgdOAboA9wuIs29bZ4CRgKdvdvAKh+NMXHGhnuaWBJODaEPsFJVV6vqXmAaMCSgTFfgc+/+LL/1fwY+VdUtqvob8CkwUETaAE1V9Rvvep+vAGdW8ViMqXFV7RC24Z4mloSTENoC6/we53jL/C0AzvHunwU0EZGW5Wzb1rtf3j4BEJGRIpIlIll5eXlhhGtMzYjE/D+ROIfAmEgJJyEEa9sPnDllNHCSiMwHTgLWA4XlbBvOPt1C1cmqmq6q6a1btw4jXGNqRqQ6hG24p4kV4Qw7zQHa+z1uB+T6F1DVXOBsABE5EDhHVbeJSA7QL2Db2d4+2wUs32+fxsQ66xA2tU04NYRMoLOIdBKRBsBQ4H3/AiLSSkR8+7oVeMG7PwMYICLNvc7kAcAMVd0A7BCRvt7ooouA9yJwPMbUGOsQNrVNyISgqoXAtbgv92XAdFVdIiLjReQMr1g/YLmI/AgcAtztbbsF+DcuqWQC471lAKOA54CVwCrg40gdlDE1wTqETW0T99dDMCaapkyx+X9M7Ksz10MwJpqqOqmcMbHEpq4wxhgDWEIwdViszDJqTKywJiNTJ9kso8aUZjUEUyfZLKPGlGYJwdRJdlKZMaVZQjB1kp1UZkxplhBMnWQnlRlTmiUEUyfZLKPGlGajjEydZSeVGbM/qyEYY4wBLCEYY4zxWEIwxhgDWEIwxhjjsYRgjDEGsIRgjDHGYwnBGGMMEGZCEJGBIrJcRFaKyJgg6zuIyCwRmS8iC0VksLc8Q0Sy/W7FIpLmrZvt7dO37uDIHpoxxpiKCHlimogkAJOA04AcIFNE3lfVpX7FxuGutfyUiHQFPgKSVXUKMMXbTw/gPVXN9tsuQ1XtmpjGGBMDwqkh9AFWqupqVd0LTAOGBJRRoKl3/yAgN8h+hgFTKxuoMcaY6hVOQmgLrPN7nOMt83cHMFxEcnC1g+uC7OcCSieEF73mon+KiAR7chEZKSJZIpKVl5cXRrimLrCrnRkTeeEkhGBf1BrweBjwkqq2AwYDr4pIyb5F5BggX1UX+22Toao9gBO824XBnlxVJ6tquqqmt27dOoxwTW3nu9rZ2rWguu9qZ5YUjKmacBJCDtDe73E7SjcJXQ5MB1DVb4BGQCu/9UMJqB2o6nrv7w7gdVzTlDEh2dXOjKke4SSETKCziHQSkQa4L/f3A8r8DPQHEJGjcAkhz3tcDzgP1/eAtyxRRFp59+sDpwOLMSYMdrUzY6pHyISgqoXAtcAMYBluNNESERkvImd4xf4BXCEiC3A1gUtU1desdCKQo6qr/XbbEJghIguBbGA98GxEjsjEvKq2/9vVzoypHrLvezv2paena1aWjVKNZ772f/8mn6Skil2cJhL7MKYuEZG5qpoeqpydqWxqVCTa/+1qZ8ZUD6shmBpVr54bGRRIBIqLaz4eY+oCqyGYmGTt/8bELksIpkbdfbdr7/eXlOSWG2OiyxKCqVHW/m9M7Ao5uZ0xkZaRYQnAmFhkNQRjjDGAJQRTCTaxnDG1kzUZmQoJPCnMN7EcWDOQMfHOagimQmxiOWNqL0sIpkJsYrnYNW0aPPVUtKMw8cyajEyFdOjgmomCLTfRM2cODB8ORUVQvz6MGBHtiEw8shqCqRA7sSz2/PorDB3qOvhPPRVGjYJZs6IdlYlHlhBMhdiJZbGluBguvNAlhTffhLfegj/+Ec45B378MdrRmXhjCcFUWEYGrFnjvozWrLFkEE0PPAD/+x9MnAg9e8JBB8F//wsJCXD66bBlS7QjNPHEEoIxceqrr2DcOLjgArjyyn3LDzsM3n3X9fWccw7s3Ru9GE18sYRgTBzKy3P9Bocd5prsRPZff9xx8PzzMHu261OIo1nuTRSFlRBEZKCILBeRlSIyJsj6DiIyS0Tmi8hCERnsLU8Wkd0iku3dnvbbpreILPL2+ZhI4EfaxLLcXPuS8dm9G3burLnn8/UbbN4M06dD06bByw0f7moQL7wADz1Uc/GZ+BUyIYhIAjAJGAR0BYaJSNeAYuNw11ruCQwFnvRbt0pV07zbVX7LnwJGAp2928DKH4YJV1WmnSgqgrffhuOPh7Zt4fLLoaCguiKNbTk58MwzcMYZ0LIltG4N771XM899//0wYwY8+iikpZVf9s474fzz4ZZbXDOSMeVS1XJvwLHADL/HtwK3BpR5BrjFr/zX3v1kYHGQfbYBfvB7PAx4JlQsvXv3VlN5r72mmpSk6n7bu1tSkltenu3bVSdOVO3UyW3TqZPq8OHu/sCBqjt21Ez80VRYqPrNN6pjx6qmpe17/Tp1Ur3uOtU+fVTr1VN98snqjeOLL9zzDB2qWlwc3jb5+S6+pCTVefOqNz4Tm4AsDfH9qu4jHTIhnAs85/f4QuCJgDJtgEVADvAb0Fv3JYRdwHzgC+AEb3k68Jnf9icAH5Tx/COBLCCrQ4cONfDS1V4dO+6fDHy3jh2Dl1+7VvUf/1Bt2tSVO+441f/8x305qqo++6xqQoJq796qv/xSU0dRc7ZuVZ0+XfWii1Rbt3avQUKC6oknqj7wgOqSJfu+lHfuVD39dFfmttvC/7KuiI0bVf/wB9XOnV2SrogNG1Tbt1dt21Y1JyfysUVSYaHquHGqF1+seuONqnffrfr006pvvqk6c6bqggXuGHbvjnak8SOSCeG8IAnh8YAyNwL/0H01hKW45qiGQEtveW9gHdAUODpIQvhvqFishlA1IsETgsj+5b79VvWCC9yXX0KC+zX63XfB9/nBB+6XZ6dOqsuXV/8xVLfly1Ufflj15JNVExPd69OihWpGhurrr6tu3lz2tgUFqldc4ba56CLVPXsiF1dRkeqAAaoNG6pmZ1duHwsWqB54oGqvXi6BxaoxY9xr2LZt6Rpt4C0pySW6tDTV/v1Vzz9fddQol1AmTlRdtCjaRxMbwk0I4UxdkQO093vcDsgNKHM5Xh+Aqn4jIo2AVqq6CdjjLZ8rIquAP3r7bBdinybCypt2orDQtTFPmABff+3Gs99wA1x3XfnTUvzlL24ky1/+An/6E3zwAfTtW22HEHFbt0JWFnz4obutWOGWd+8Oo0e74+rbFxLD+E9JTHT9Cu3bw7/+BRs2wH/+A02aVD3Oe++FTz5x+09Nrdw+UlJg6lTX73HRRe5EtnoxNs7wrbfgvvvcMNqnvSEou3e78yk2bw59W7fO/f3tN9f5DtCrF1x8MQwb5vp6TDlCZQzcfEergU5AA2BN1JU9AAAYrUlEQVQB0C2gzMfAJd79o3Bf7gK0BhK85YcB64EW3uNMoK9X7mNgcKhYrIZQNcH6EA44wP36TU52jw87TPXRRyveJLFiheoRR7j9vfde9cRfWfn5qgsXqr71luo996heeqlr/vI1A4H75T1okOqkSapr1lT9OV94wdWu0tJUc3Ortq/Zs12/wd/+FpmmqEceccc8ZkzV9xVJixerNm6s2rev6u+/V21fRUWuWWniRNWePd3xJiaqnnGG+xxUdf/xhkg1Gbl9MRj4EVgFjPWWjQfO8O53Bf7PSxbZwABv+TnAEm/5POCvfvtMBxZ7+3wCkFBxWEKoutde29eX0KSJaqNG7v4JJ6i+/fa+/oHK2LRpX+fqU09FLOSwFBS4pPThh6oTJqhefbXqqaeqduhQupmhTRvVk05yzTsPPOC2qY4mlI8/dl9wHTuqLltWuX388ouL949/rHiSLktxseqVV7rX4sUXI7PPqvrtN/eD4tBDVdevj/z+Fy5UHT3a7d/XDHj11a55tDr6e2JNRBNCrNwsIVTenj2q33/vfv0PGeK+tBMSVIcNc8sjpSY6V1VV9+5VnTrVHUuXLvva+323gw5yyWn4cNXx413ZuXMj96Uarqws1YMPdl9Ac+ZUbNvCQpfUGjVy7f+RtHeva3OvX9/VQKKpqEh18GD3Hn71VfU+V0GBS9RDh+77MdSli6s5/vxz9T53ZX33neppp6lu21b5fVhCqOPWr3cjgkaPds0jvg8/qLZrp3rzzdX3DxDYubp3b+T2/dtv7ld9+/Zu/8nJqueco3rrre7X7pw5rqYSS7/6Vq1yI4MaNXK1sHD9+9/uGJ99tnri2rLFfRm2aOFqV9Hyr3+545w0qWafd+tW99oef7yWDK7o31/15ZdjYyh1UZHqQw+5RNmhg2tSqyxLCLWQr7lHxP31nT+wZ4+r+k6c6EYH+TeTNGigeuyxqjfc4IZQrltXM7EWF7tf5uB+3VT1l/nKlar/7/+5Jhhwo4D++1/3TxMP8vJc27iI6uOPhy4/c6arxWVkVG9yW7lStWVLlxi2bKm+5ynLu++69/PSS6ObxFeuVL399n3n2jRu7Ia9zpwZnbjy8lT/8hcXy5lnlj+6LRyWEGqZYB3CiYnul2fDhvuWtW/vht5NmOBOpIp255mvc7Vnz4p3rhYXq375pepZZ7kv0vr1XY1j/vzqibW67drlmrjA1dDKSma//OLaurt0qZlfql984V7bU06JbG0ulGXLXD9WenrsnFNQVOQ+c5df7mID198U6Sa78nzxhRty26CB+/EQiYRkCaGWKeuksoYN3cljb74ZuyccffRRxTpX9+5VnTLFfVH4OgDHjq2ezsaaVljoxsmD+/UfeK6Cf7/BwoU1F9dLL7mYRo6smV/E27apHnmkG+kVq233u3a5M89btHC1teuuq95aVGGh6p13uuc64ojInlVuCaEWWbEieDIIdlJZrMrMDN25umWL6n33uV9Hvs6+p55y/5i1SXGxO/sWXJv11q371t15p1v+3HM1H9ett7rnHjeuaqPNQikqcs0gCQmqs2ZV3/NEyubNbkRSvXqqrVq5fodIN1Xm5rpmUN8PhUgPfrCEUAvs3OlG6jRoUPZZxmVNOxGLyupc/fFH1Wuu2dck1r+/OwM6XvoHKuvll12zX0qKq919/rl7n4cPj067dVGR6oUXuvfgmGMqP1Q2lLvucs8xYUL17L+6zJ/vBmiA6tFHl332fkX973+upnTAAa6JtTree0sIcay4WHXaNDcaCNw/6eOPV25iuliTl+e+bETcL9EhQ/b1D1xySeWnZYhXM2a46STat1c95BDXjBLNES7FxW6KjhYtXHPk/fdHtrbw4Yfu/a7uzvLqUlys+uqr+85nuOwyN8dUZezdq3rLLW4/3bu7ubGqiyWEOLVokWq/fu6dSUvbv3mlrFFG8WbXLnfGKLgRLuPGVf1s3ng2b577gjnggNiZe2fDBtes46stLF1a9X2uWOHOD0lLi/9mwG3b3JDuxER3TI8+6oZbh2vNGjf6z9dvU92vhyWEOPPbb6rXX+/aVZs3d51Z1dmOG20FBa6JJD8/2pHEho0bq6+JprICawv33VexLz1/O3a4X8EtWqiuXh3ZOKNp2TI3rNr3Kz+cPpF33lFt1syNYpo2rdpDVFVLCHGjqMi1Gx58sPvlf+WVrlnFmFjxyy9u6C+4s78r2rRRXKx63nmuU/aTT6onxmgqLnZ9Yr6RgBdcEPx8n927Va+91pXp3dud+1BTLCHEgcxMVx0HV32cOzfaERkTnK9fq2VLN8jh3nvDry3cf7/7jN9/f/XGGG35+e7ktkaNXP/ePffsOw9o+fJ9F1b6+99r/vwgSwgxbNMm1REjXI3gkEPcaJPaPqLG1A6//KJ69tlaMtImVG3hk09czeC88+KzE7kyVq/e1/9yxBFuKPGBB7rmsvffj05MlhBiUEGB6hNPuPbDxER3NSj/MejGxINwawurV7svwe7dY2NuoJr2v/+5WWrBzZcUzRPwwk0I4srGh/T0dM3Kyop2GJVSWAj9+8OXX7q/jz0GXbtGOypjKm/TJrj6ancRoPR0eOkl6NbNrcvPh+OOgzVrIDMTjjgimpFGz969MGcOnHhieBdZqi4iMldV00OVi7HrJdVejzziksHTT8Onn1oyMPHv4IPdFc7eeMN98ffq5a7sVlgII0fCggUwZUrdTQYADRrAKadENxlUhNUQasCKFe7yhYMGwdtvRzsaYyJv0ya45hqXIDp0gJ9/hn//G8aNi3ZkBqyGEDNU3a+lhg3hiSeiHY0x1ePgg901mqdPd9dAPvdcuO22aEdlKiqshCAiA0VkuYisFJExQdZ3EJFZIjJfRBaKyGBv+WkiMldEFnl/T/HbZra3z2zvdnDkDit2PPecuwj9uee6i9DXqwfJya4qbUxtc955kJvrEkM9+7kZd0K2bIlIAjAJOA3IATJF5H1VXepXbBwwXVWfEpGuwEdAMvAr7jrKuSLSHZgBtPXbLkNV468NKEy5uXDTTa6/4PXX3S8ngLVrXa0BICMjevEZUx3ipb3clBZODu8DrFTV1aq6F5gGDAkoo0BT7/5BQC6Aqs5X1Vxv+RKgkYg0rHrYsU/Vtanu2QNbt+5LBj75+TB2bHRiM8aYYMJJCG2BdX6Pc9j/Vz7AHcBwEcnB1Q6uC7Kfc4D5qrrHb9mLXnPRP0VEgj25iIwUkSwRycrLywsj3Njw9tvw7rtw552wYUPwMj//XLMxGWNMecJJCMG+qAOHJg0DXlLVdsBg4FURKdm3iHQD7geu9NsmQ1V7ACd4twuDPbmqTlbVdFVNb926dRjhRt9vv8G117pheDfe6EZdBFPWcmOMiYZwEkIO0N7vcTu8JiE/lwPTAVT1G6AR0ApARNoB7wAXqeoq3waqut77uwN4Hdc0VSuMHg15efD886499e67ISlp/zJJSW65McbEinASQibQWUQ6iUgDYCjwfkCZn4H+ACJyFC4h5IlIM+BD4FZV/T9fYRFJFBFfwqgPnA4srurBxILPP4cXXnCdyWlpbllGBkyeDB07goj7O3mydSgbY2JLWCemecNIJwIJwAuqereIjMfNj/G+N7LoWeBAXHPSzar6iYiMA24FVvjtbgCwC/gSqO/t8zPgRlUtKi+OWD8xLT8fevSAhAR3luYBB0Q7ImOMCf/ENDtTOYJGj4aHH3bnHZx0UrSjMcYYx85UrmGZmTBhgju/wJKBMSYeWUKIgIICGDECDj0UHngg2tEYY0zl2DmFEfDgg7BwoTvv4KCDoh2NMcZUjtUQqmj5chg/3s3hMiTw/G1jjIkjlhCqoLjYNRUlJcHjj0c7GmOMqRprMqqCZ55xV0N68UU45JBoR2OMMVVjNYRKysmBW26BU0+Fiy+OdjTGGFN1lhAqQRVGjYKiIldLCD4tnzHGxBdrMqqE6dPhgw/cSWiHHRbtaIwxJjKshlBBmzfDddfB0UfD9ddHOxpjjIkcqyFU0I03uumtP/vMzVlkjDG1hdUQKmDGDHjlFRgzBlJSoh2NMcZEliWEMO3cCVdeCUceCePGRTsaY4yJPGsyCtM//wlr17rzDhrWiatCG2PqGqshhOGuu2DiRHc/IwOmTIluPMYYUx0sIYTw6qtw++37Hq9d66a4tqRgjKltLCGE8Pe/uzmL/OXnw9ix0YnHGGOqS1gJQUQGishyEVkpImOCrO8gIrNEZL6ILPQuuelbd6u33XIR+XO4+4wFmzbBli3B1/38c83GYowx1S1kQhCRBGASMAjoCgzzrqHsbxwwXVV7AkOBJ71tu3qPuwEDgSdFJCHMfUbdzTeXva5Dh5qLwxhjakI4NYQ+wEpVXa2qe4FpQODM/wo09e4fBOR694cA01R1j6r+BKz09hfOPqPqyy/h5Zfhr39101v7S0qCu++OTlzGGFNdwkkIbYF1fo9zvGX+7gCGi0gO8BFwXYhtw9knACIyUkSyRCQrLy8vjHCrrqAArr4aOnaEadNg8mR3X8T9nTzZjTYyxpjaJJyEEGwuTw14PAx4SVXbAYOBV0WkXjnbhrNPt1B1sqqmq2p669atwwi36iZOhCVL3EVvkpLcl/+aNa5zec0aSwbGmNopnBPTcoD2fo/bsa9JyOdyXB8BqvqNiDQCWoXYNtQ+o+Lnn+GOO9zlMP/612hHY4wxNSecGkIm0FlEOolIA1wn8fsBZX4G+gOIyFFAIyDPKzdURBqKSCegM/B9mPuMCt8Mpo8+Gt04jDGmpoWsIahqoYhcC8wAEoAXVHWJiIwHslT1feAfwLMicgOu6ecSVVVgiYhMB5YChcA1qloEEGyf1XB8FfLBB/Duu3Dffa6vwBhj6hJx39vxIT09XbOysqpl3/n50K2b6zOYPx8aNKiWpzHGmBonInNVNT1UOZvcznPPPa7DePZsSwbGmLrJpq4AfvgBHngALrwQTjop2tEYY0x01PmEoArXXAONG8ODD0Y7GmOMiZ4632Q0dSrMnAlPPgmHHBLtaIwxJnrqdA1h2zZ3jeSjj3ZTWhtjTF1Wp2sI48ZBXh58+CEkJEQ7GmOMia46W0OYO9c1E119NfTuHe1ojDEm+upkQigqglGjoHVr+Pe/ox2NMcbEhjrZZPTss5CZ6S6D2axZtKMxxpjYUOdqCBs3wq23wimnwLBh0Y7GGGNiR51LCDffDLt2waRJ7voGxhhjnDqVEL74Al55BW66CY48MtrRGGNMbKkzCWHvXteRnJwMY8dGOxpjjIk9daZTecIEWLYM/vvf0tdINsYYU0dqCGvXwvjxcOaZcPrp0Y7GGGNiU51ICHYVNGOMCa1ONBmNGOGuj9yhQ7QjMcaY2BVWDUFEBorIchFZKSJjgqyfICLZ3u1HEdnqLT/Zb3m2iPwuImd6614SkZ/81qVF9tD2Of10uPzy6tq7McbUDiFrCCKSAEwCTgNygEwReV9Vl/rKqOoNfuWvA3p6y2cBad7yFsBK4BO/3d+kqm9F4DiMMcZUUTg1hD7ASlVdrap7gWnAkHLKDwOmBll+LvCxquZXPExjjDHVLZyE0BZY5/c4x1tWioh0BDoBM4OsHkrpRHG3iCz0mpwalrHPkSKSJSJZeXl5YYRrjDGmMsJJCMEmeNAyyg4F3lLVov12INIG6AHM8Ft8K3AkcDTQArgl2A5VdbKqpqtqeuvWrcMI1xhjTGWEkxBygPZ+j9sBuWWUDVYLADgfeEdVC3wLVHWDOnuAF3FNU8YYY6IknISQCXQWkU4i0gD3pf9+YCER6QI0B74Jso9S/QperQEREeBMYHHFQjfGGBNJIUcZqWqhiFyLa+5JAF5Q1SUiMh7IUlVfchgGTFPV/ZqTRCQZV8P4ImDXU0SkNa5JKhu4qioHYowxpmok4Ps7pqWnp2tWVla0wzDGmLgiInNVNT1UuToxdYUxxpjQLCEYY4wBLCEYY4zxWEIwxhgDWEIwxhjjsYRgjDEGsIRgjDHGYwnBGGMMYAnBGGOMxxKCMcYYwBKCMcYYjyUEY4wxgCUEY4wxHksIxhhjAEsIxhhjPJYQjDHGAGEmBBEZKCLLRWSliIwJsn6CiGR7tx9FZKvfuiK/de/7Le8kIt+JyAoRecO7PKcxxpgoCZkQRCQBmAQMAroCw0Skq38ZVb1BVdNUNQ14HHjbb/Vu3zpVPcNv+f3ABFXtDPwGXF7FYzHGGFMF4dQQ+gArVXW1qu4FpgFDyik/DJha3g5FRIBTgLe8RS8DZ4YRizHGmGoSTkJoC6zze5zjLStFRDoCnYCZfosbiUiWiHwrIr4v/ZbAVlUtDLVPY4wxNSOchCBBlmkZZYcCb6lqkd+yDt7Fnf8GTBSRwyuyTxEZ6SWUrLy8vDDC3d+UKZCcDPXqub9TplR4F8YYUyeEkxBygPZ+j9sBuWWUHUpAc5Gq5np/VwOzgZ7Ar0AzEUkMtU9Vnayq6aqa3rp16zDC3WfKFBg5EtauBVX3d+RISwrGGBNMOAkhE+jsjQpqgPvSfz+wkIh0AZoD3/gtay4iDb37rYDjgKWqqsAs4Fyv6MXAe1U5kGDGjoX8/P2X5ee75cYYY/YXMiF47fzXAjOAZcB0VV0iIuNFxH/U0DBgmvdl73MUkCUiC3AJ4D5VXeqtuwW4UURW4voUnq/64ezv558rttwYY+oy2f/7O7alp6drVlZW2OWTk10zUaCOHWHNmoiFZYwxMU1E5np9ueWq1Wcq3303JCXtvywpyS03xhizv1qdEDIyYPJkVyMQcX8nT3bLjTHG7C8xdJH4lpFhCcAYY8JRq2sIxhhjwmcJwRhjDGAJwRhjjMcSgjHGGMASgjHGGE9cnZgmInlAkFPNYkYr3DxN8SBeYrU4Iyte4oT4iTUe4uyoqiEng4urhBDrRCQrnLMBY0G8xGpxRla8xAnxE2u8xBkOazIyxhgDWEIwxhjjsYQQWZOjHUAFxEusFmdkxUucED+xxkucIVkfgjHGGMBqCMYYYzyWEIwxxgCWECpMRNqLyCwRWSYiS0Tk+iBl+onINhHJ9m7/ikasXixrRGSRF0epqwuJ85iIrBSRhSLSKwoxdvF7rbJFZLuI/D2gTFReUxF5QUQ2ichiv2UtRORTEVnh/W1exrYXe2VWiMjFUYjzQRH5wXtf3xGRZmVsW+5npIZivUNE1vu9v4PL2HagiCz3Pq9johDnG34xrhGR7DK2rdHXNGJU1W4VuAFtgF7e/SbAj0DXgDL9gA+iHasXyxqgVTnrBwMfAwL0Bb6LcrwJwC+4E2mi/poCJwK9gMV+yx4Axnj3xwD3B9muBbDa+9vcu9+8huMcACR69+8PFmc4n5EaivUOYHQYn41VwGFAA2BB4P9edccZsP5h4F+x8JpG6mY1hApS1Q2qOs+7vwN3nem20Y2qSoYAr6jzLdBMRNpEMZ7+wCpVjYkz0lX1S2BLwOIhwMve/ZeBM4Ns+mfgU1Xdoqq/AZ8CA2syTlX9RN010QG+BdpV1/NXRBmvaTj6ACtVdbWq7gWm4d6LalFenCIiwPnA1Op6/miwhFAFIpIM9AS+C7L6WBFZICIfi0i3Gg1sfwp8IiJzRWRkkPVtgXV+j3OIboIbStn/ZLHymh6iqhvA/UAADg5SJtZe18twNcFgQn1Gasq1XvPWC2U0w8XSa3oCsFFVV5SxPlZe0wqxhFBJInIg8B/g76q6PWD1PFyTRyrwOPBuTcfn5zhV7QUMAq4RkRMD1kuQbaIyFllEGgBnAG8GWR1Lr2k4Yul1HQsUAlPKKBLqM1ITngIOB9KADbjmmEAx85oCwyi/dhALr2mFWUKoBBGpj0sGU1T17cD1qrpdVXd69z8C6otIqxoO0xdLrvd3E/AOrtrtLwdo7/e4HZBbM9GVMgiYp6obA1fE0msKbPQ1q3l/NwUpExOvq9eZfTqQoV7jdqAwPiPVTlU3qmqRqhYDz5YRQ6y8ponA2cAbZZWJhde0MiwhVJDXdvg8sExVHymjzKFeOUSkD+513lxzUZbE0VhEmvju4zoZFwcUex+4yBtt1BfY5msOiYIyf3XFymvqeR/wjRq6GHgvSJkZwAARae41fwzwltUYERkI3AKcoar5ZZQJ5zNS7QL6rc4qI4ZMoLOIdPJqk0Nx70VNOxX4QVVzgq2Mlde0UqLdqx1vN+B4XDV1IZDt3QYDVwFXeWWuBZbgRkF8C/wpSrEe5sWwwItnrLfcP1YBJuFGbywC0qMUaxLuC/4gv2VRf01xCWoDUID7hXo50BL4HFjh/W3hlU0HnvPb9jJgpXe7NApxrsS1ufs+p097Zf8AfFTeZyQKsb7qff4W4r7k2wTG6j0ejBvZt6q6Yw0Wp7f8Jd/n0q9sVF/TSN1s6gpjjDGANRkZY4zxWEIwxhgDWEIwxhjjsYRgjDEGsIRgjDHGYwnBGGMMYAnBGGOM5/8DQTl7jcrqf58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
