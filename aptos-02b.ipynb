{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Repository source: https://github.com/qubvel/efficientnet\n",
    "sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n",
    "from efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                        ModelCheckpoint, CSVLogger)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Files and file sizes\n",
      "sample_submission.csv         | 0.03 MB\n",
      "train.csv                     | 0.05 MB\n",
      "test.csv                      | 0.03 MB\n",
      "train_images                  | 0.14 MB\n",
      "test_images                   | 0.07 MB\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import relu, elu, hard_sigmoid, softmax\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5-C.h5'\n",
    "\n",
    "# Set seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# For keeping time. GPU limit for this competition is set to Â± 9 hours.\n",
    "t_start = time.time()\n",
    "\n",
    "# File sizes and specifications\n",
    "print('\\n# Files and file sizes')\n",
    "for file in os.listdir(KAGGLE_DIR):\n",
    "    print('{}| {} MB'.format(file.ljust(30), \n",
    "                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet-keras-weights-b0b5',\n",
       " 'aptos2019-blindness-detection',\n",
       " 'diabetic-retinopathy-resized-train-15-19-dg',\n",
       " 'efficientnet',\n",
       " 'aptos-00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-A)\n",
      "Training images: 3662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              1\n",
       "3  002c21358ce6          0  002c21358ce6.png              0\n",
       "4  005b95c28852          0  005b95c28852.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-B)\n",
      "Training images: 1857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              0\n",
       "3  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "4  00a8624548a9          2  00a8624548a9.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-C)\n",
      "Training images: 1487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "      <td>00b74780d31d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              0\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "3  00a8624548a9          2  00a8624548a9.png              0\n",
       "4  00b74780d31d          2  00b74780d31d.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-D)\n",
      "Training images: 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104b032c141</td>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0243404e8a00</td>\n",
       "      <td>4</td>\n",
       "      <td>0243404e8a00.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02685f13cefd</td>\n",
       "      <td>4</td>\n",
       "      <td>02685f13cefd.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  001639a390f0          4  001639a390f0.png              1\n",
       "1  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "2  0104b032c141          3  0104b032c141.png              0\n",
       "3  0243404e8a00          4  0243404e8a00.png              1\n",
       "4  02685f13cefd          4  02685f13cefd.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path specifications\n",
    "TRAIN_DF_A_PATH = \"../input/aptos-00/df_train_A.csv\"\n",
    "TRAIN_DF_B_PATH = \"../input/aptos-00/df_train_B.csv\"\n",
    "TRAIN_DF_C_PATH = \"../input/aptos-00/df_train_C.csv\"\n",
    "TRAIN_DF_D_PATH = \"../input/aptos-00/df_train_D.csv\"\n",
    "\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-A)\")\n",
    "train_df_A = pd.read_csv(TRAIN_DF_A_PATH)\n",
    "print(f\"Training images: {train_df_A.shape[0]}\")\n",
    "display(train_df_A.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-B)\")\n",
    "train_df_B = pd.read_csv(TRAIN_DF_B_PATH)\n",
    "print(f\"Training images: {train_df_B.shape[0]}\")\n",
    "display(train_df_B.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-C)\")\n",
    "train_df_C = pd.read_csv(TRAIN_DF_C_PATH)\n",
    "print(f\"Training images: {train_df_C.shape[0]}\")\n",
    "display(train_df_C.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-D)\")\n",
    "train_df_D = pd.read_csv(TRAIN_DF_D_PATH)\n",
    "print(f\"Training images: {train_df_D.shape[0]}\")\n",
    "display(train_df_D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_B\n",
    "df0 = df.iloc[:0,:]\n",
    "df1 = df.iloc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DGTraining.csv',\n",
       " 'testLabels15.csv',\n",
       " 'trainLabels15.csv',\n",
       " 'trainLabels19.csv',\n",
       " 'DGTesting.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels15.csv')\n",
    "df_x19 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x19['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x15['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = df_x15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_x15 = df_x15[df_x15['diagnosis'] == 1]\n",
    "df_2_x15 = df_x15[df_x15['diagnosis'] == 2]\n",
    "df_3_x15 = df_x15[df_x15['diagnosis'] == 3]\n",
    "df_4_x15 = df_x15[df_x15['diagnosis'] == 4]\n",
    "\n",
    "df_1_x19 = df_x19[df_x19['diagnosis'] == 1]\n",
    "df_2_x19 = df_x19[df_x19['diagnosis'] == 2]\n",
    "df_3_x19 = df_x19[df_x19['diagnosis'] == 3]\n",
    "df_4_x19 = df_x19[df_x19['diagnosis'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_1_x15['binary_target'] = 0\\ndf_2_x15['binary_target'] = 1\\ndf_3_x15['binary_target'] = 1\\ndf_4_x15['binary_target'] = 1\\n\\ndf_1_x19['binary_target'] = 0\\ndf_2_x19['binary_target'] = 1\\ndf_3_x19['binary_target'] = 1\\ndf_4_x19['binary_target'] = 1\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_1_x15['binary_target'] = 0\n",
    "df_2_x15['binary_target'] = 1\n",
    "df_3_x15['binary_target'] = 1\n",
    "df_4_x15['binary_target'] = 1\n",
    "\n",
    "df_1_x19['binary_target'] = 0\n",
    "df_2_x19['binary_target'] = 1\n",
    "df_3_x19['binary_target'] = 1\n",
    "df_4_x19['binary_target'] = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1_x15, df_2_x15,df_3_x15, df_4_x15, df_1_x19, df_2_x19, df_3_x19, df_4_x19], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file_name column to df_train and df_test\n",
    "\n",
    "def create_fname(x):\n",
    "    \n",
    "    fname = str(x) + '.jpg'\n",
    "    \n",
    "    return fname\n",
    "\n",
    "df['file_name'] = df['id_code'].apply(create_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    6291\n",
       "1    2813\n",
       "3    1066\n",
       "4    1003\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "\n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_0 = df[df['binary_target'] == 0]\\ndf_1 = df[df['binary_target'] == 1]\\n\\n\\ndf_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\\n\\ndf_data = shuffle(df_data)\\n\\nprint(df_data.shape)\\n\\ndf_data.head()\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_0 = df[df['binary_target'] == 0]\n",
    "df_1 = df[df['binary_target'] == 1]\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11173, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>2010_left</td>\n",
       "      <td>2</td>\n",
       "      <td>2010_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>12101_left</td>\n",
       "      <td>2</td>\n",
       "      <td>12101_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34412</th>\n",
       "      <td>43486_left</td>\n",
       "      <td>2</td>\n",
       "      <td>43486_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>22098b1fe461</td>\n",
       "      <td>1</td>\n",
       "      <td>22098b1fe461.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22528</th>\n",
       "      <td>28413_left</td>\n",
       "      <td>2</td>\n",
       "      <td>28413_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_code  diagnosis         file_name\n",
       "1598      2010_left          2     2010_left.jpg\n",
       "9606     12101_left          2    12101_left.jpg\n",
       "34412    43486_left          2    43486_left.jpg\n",
       "476    22098b1fe461          1  22098b1fe461.jpg\n",
       "22528    28413_left          2    28413_left.jpg"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10055, 3)\n",
      "(1118, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_data, test_size=0.1, random_state=11)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5663\n",
       "1    2529\n",
       "3     958\n",
       "4     905\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_train['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    628\n",
       "1    284\n",
       "3    108\n",
       "4     98\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_val['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>12478_right</td>\n",
       "      <td>2</td>\n",
       "      <td>12478_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28121</th>\n",
       "      <td>35609_right</td>\n",
       "      <td>3</td>\n",
       "      <td>35609_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16026</th>\n",
       "      <td>20095_left</td>\n",
       "      <td>2</td>\n",
       "      <td>20095_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22267</th>\n",
       "      <td>28077_right</td>\n",
       "      <td>4</td>\n",
       "      <td>28077_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15296</th>\n",
       "      <td>19158_left</td>\n",
       "      <td>1</td>\n",
       "      <td>19158_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis        file_name\n",
       "9901   12478_right          2  12478_right.jpg\n",
       "28121  35609_right          3  35609_right.jpg\n",
       "16026   20095_left          2   20095_left.jpg\n",
       "22267  28077_right          4  28077_right.jpg\n",
       "15296   19158_left          1   19158_left.jpg"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " 'train_images',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/aptos2019-blindness-detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (456, 456))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = '../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG/'\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create sub folders inside 'base_dir':\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "a_1 = os.path.join(train_dir, 'a_1')\n",
    "os.mkdir(a_1)\n",
    "a_2 = os.path.join(train_dir, 'a_2')\n",
    "os.mkdir(a_2)\n",
    "a_3 = os.path.join(train_dir, 'a_3')\n",
    "os.mkdir(a_3)\n",
    "a_4 = os.path.join(train_dir, 'a_4')\n",
    "os.mkdir(a_4)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "a_1 = os.path.join(val_dir, 'a_1')\n",
    "os.mkdir(a_1)\n",
    "a_2 = os.path.join(val_dir, 'a_2')\n",
    "os.mkdir(a_2)\n",
    "a_3 = os.path.join(val_dir, 'a_3')\n",
    "os.mkdir(a_3)\n",
    "a_4 = os.path.join(val_dir, 'a_4')\n",
    "os.mkdir(a_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_dir', 'train_dir']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the folders exist\n",
    "os.listdir('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file_name as the index in df_data\n",
    "df_data.set_index('file_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['file_name'])\n",
    "\n",
    "# ============================\n",
    "# Transfer the train images\n",
    "# ============================\n",
    "\n",
    "for fname in train_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'diagnosis']\n",
    "    \n",
    "    if label == 1:\n",
    "        sub_folder = 'a_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "    if label == 2:\n",
    "        sub_folder = 'a_2'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "    if label == 3:\n",
    "        sub_folder = 'a_3'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "    if label == 4:\n",
    "        sub_folder = 'a_4'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "# ============================\n",
    "# Transfer the val images\n",
    "# ============================\n",
    "\n",
    "# Get a list of train and val images\n",
    "val_list = list(df_val['file_name'])\n",
    "\n",
    "for fname in val_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'diagnosis']\n",
    "    \n",
    "    if label == 1:\n",
    "        sub_folder = 'a_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 2:\n",
    "        sub_folder = 'a_2'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "    if label == 3:\n",
    "        sub_folder = 'a_3'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 4:\n",
    "        sub_folder = 'a_4'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10055 images belonging to 4 classes.\n",
      "Found 1118 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "val_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "# Get the number of train and val steps\n",
    "train_steps = np.ceil(num_train_samples // train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples // val_batch_size)\n",
    "# Pre-process the input images in the same way as the ImageNet images \n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= preprocess_image,\n",
    "    rescale=1 / 128.)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=4,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in EfficientNetB5\n",
    "effnet = EfficientNetB5(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "effnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all Batch Normalization layers by Group Normalization layers\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=16, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 28,176,244\n",
      "Trainable params: 28,176,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(4, activation=softmax))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_1': 0, 'a_2': 1, 'a_3': 2, 'a_4': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # Class 0\n",
    "    1: 1.0, # Class 1\n",
    "    2: 1.0, # Class 2\n",
    "    3: 1.0, # Class 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "1256/1256 [==============================] - 1221s 972ms/step - loss: 1.1257 - categorical_accuracy: 0.5347 - val_loss: 1.0096 - val_categorical_accuracy: 0.5585\n",
      "Epoch 2/17\n",
      "1256/1256 [==============================] - 1179s 939ms/step - loss: 0.9607 - categorical_accuracy: 0.5808 - val_loss: 0.8948 - val_categorical_accuracy: 0.6072\n",
      "Epoch 3/17\n",
      "1256/1256 [==============================] - 1177s 937ms/step - loss: 0.8769 - categorical_accuracy: 0.6186 - val_loss: 0.8308 - val_categorical_accuracy: 0.6243\n",
      "Epoch 4/17\n",
      "1256/1256 [==============================] - 1176s 937ms/step - loss: 0.8232 - categorical_accuracy: 0.6419 - val_loss: 0.8086 - val_categorical_accuracy: 0.6468\n",
      "Epoch 5/17\n",
      " 325/1256 [======>.......................] - ETA: 14:09 - loss: 0.7735 - categorical_accuracy: 0.6707"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "\n",
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr, early_stopper, csv_logger]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_gen.samples // train_batch_size, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=17, verbose=1,\n",
    "                   callbacks=[reduce_lr, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.734149</td>\n",
       "      <td>0.638274</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.679279</td>\n",
       "      <td>0.758754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  categorical_accuracy      loss       lr  val_categorical_accuracy  \\\n",
       "9      9              0.734149  0.638274  0.00001                  0.679279   \n",
       "\n",
       "   val_loss  \n",
       "9  0.758754  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training log\n",
    "df = pd.read_csv('training_log.csv')\n",
    "\n",
    "# we are monitoring val_loss\n",
    "best_acc = df['val_categorical_accuracy'].max()\n",
    "\n",
    "# display the row with the best accuracy\n",
    "df[df['val_categorical_accuracy'] == best_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7e1dd57fcc52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_categorical_accuracy\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model.evaluate_generator(test_gen, \n\u001b[0m\u001b[1;32m      6\u001b[0m                         steps=len(df_val))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_gen' is not defined"
     ]
    }
   ],
   "source": [
    "# Here the best epoch will be used.\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_categorical_accuracy = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_categorical_accuracy:', val_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
