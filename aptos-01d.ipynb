{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Repository source: https://github.com/qubvel/efficientnet\n",
    "sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n",
    "from efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                        ModelCheckpoint, CSVLogger)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Files and file sizes\n",
      "sample_submission.csv         | 0.03 MB\n",
      "test_images                   | 0.07 MB\n",
      "train_images                  | 0.13 MB\n",
      "test.csv                      | 0.03 MB\n",
      "train.csv                     | 0.05 MB\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import relu, elu, sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5-C.h5'\n",
    "\n",
    "# Set seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# For keeping time. GPU limit for this competition is set to Â± 9 hours.\n",
    "t_start = time.time()\n",
    "\n",
    "# File sizes and specifications\n",
    "print('\\n# Files and file sizes')\n",
    "for file in os.listdir(KAGGLE_DIR):\n",
    "    print('{}| {} MB'.format(file.ljust(30), \n",
    "                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet-keras-weights-b0b5',\n",
       " 'aptos2019-blindness-detection',\n",
       " 'diabetic-retinopathy-resized-train-15-19-dg',\n",
       " 'efficientnet',\n",
       " 'aptos-00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-A)\n",
      "Training images: 3662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              1\n",
       "3  002c21358ce6          0  002c21358ce6.png              0\n",
       "4  005b95c28852          0  005b95c28852.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-B)\n",
      "Training images: 1857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              0\n",
       "3  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "4  00a8624548a9          2  00a8624548a9.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-C)\n",
      "Training images: 1487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "      <td>00b74780d31d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              0\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "3  00a8624548a9          2  00a8624548a9.png              0\n",
       "4  00b74780d31d          2  00b74780d31d.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-D)\n",
      "Training images: 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104b032c141</td>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0243404e8a00</td>\n",
       "      <td>4</td>\n",
       "      <td>0243404e8a00.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02685f13cefd</td>\n",
       "      <td>4</td>\n",
       "      <td>02685f13cefd.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  001639a390f0          4  001639a390f0.png              1\n",
       "1  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "2  0104b032c141          3  0104b032c141.png              0\n",
       "3  0243404e8a00          4  0243404e8a00.png              1\n",
       "4  02685f13cefd          4  02685f13cefd.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path specifications\n",
    "TRAIN_DF_A_PATH = \"../input/aptos-00/df_train_A.csv\"\n",
    "TRAIN_DF_B_PATH = \"../input/aptos-00/df_train_B.csv\"\n",
    "TRAIN_DF_C_PATH = \"../input/aptos-00/df_train_C.csv\"\n",
    "TRAIN_DF_D_PATH = \"../input/aptos-00/df_train_D.csv\"\n",
    "\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-A)\")\n",
    "train_df_A = pd.read_csv(TRAIN_DF_A_PATH)\n",
    "print(f\"Training images: {train_df_A.shape[0]}\")\n",
    "display(train_df_A.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-B)\")\n",
    "train_df_B = pd.read_csv(TRAIN_DF_B_PATH)\n",
    "print(f\"Training images: {train_df_B.shape[0]}\")\n",
    "display(train_df_B.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-C)\")\n",
    "train_df_C = pd.read_csv(TRAIN_DF_C_PATH)\n",
    "print(f\"Training images: {train_df_C.shape[0]}\")\n",
    "display(train_df_C.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-D)\")\n",
    "train_df_D = pd.read_csv(TRAIN_DF_D_PATH)\n",
    "print(f\"Training images: {train_df_D.shape[0]}\")\n",
    "display(train_df_D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_D\n",
    "df0 = df.iloc[:0,:]\n",
    "df1 = df.iloc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DGTraining.csv',\n",
       " 'trainLabels19.csv',\n",
       " 'DGTesting.csv',\n",
       " 'testLabels15.csv',\n",
       " 'trainLabels15.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels15.csv')\n",
    "df_x19 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x19['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x15['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = df_x15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_x15 = df_x15[df_x15['diagnosis'] == 3]\n",
    "df_4_x15 = df_x15[df_x15['diagnosis'] == 4]\n",
    "\n",
    "df_3_x19 = df_x19[df_x19['diagnosis'] == 3]\n",
    "df_4_x19 = df_x19[df_x19['diagnosis'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_x15['binary_target'] = 0\n",
    "df_4_x15['binary_target'] = 1\n",
    "\n",
    "df_3_x19['binary_target'] = 0\n",
    "df_4_x19['binary_target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_3_x15, df_4_x15, df_3_x19, df_4_x19], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file_name column to df_train and df_test\n",
    "\n",
    "def create_fname(x):\n",
    "    \n",
    "    fname = str(x) + '.jpg'\n",
    "    \n",
    "    return fname\n",
    "\n",
    "df['file_name'] = df['id_code'].apply(create_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1066\n",
       "1    1003\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "\n",
    "df['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>12279_left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12279_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>11734_left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11734_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>14129_left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14129_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>14844_right</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14844_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>8073_left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8073_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code  diagnosis  binary_target        file_name\n",
       "234    12279_left          3              0   12279_left.jpg\n",
       "222    11734_left          3              0   11734_left.jpg\n",
       "266    14129_left          3              0   14129_left.jpg\n",
       "1289  14844_right          4              1  14844_right.jpg\n",
       "148     8073_left          3              0    8073_left.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df[df['binary_target'] == 0]\n",
    "df_1 = df[df['binary_target'] == 1]\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1066\n",
       "1    1003\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new target distribution\n",
    "\n",
    "df_data['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1862, 4)\n",
      "(207, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_data, test_size=0.1, random_state=11)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    954\n",
       "1    908\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_train['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    112\n",
       "1     95\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_val['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create sub folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "# val_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "a_0 = os.path.join(train_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(train_dir, 'b_1')\n",
    "os.mkdir(b_1)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "a_0 = os.path.join(val_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(val_dir, 'b_1')\n",
    "os.mkdir(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_dir', 'train_dir']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the folders exist\n",
    "os.listdir('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>35704_right</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35704_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>97da093947e8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>97da093947e8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3096_right</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3096_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>41903_left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41903_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>28976_right</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28976_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis  binary_target         file_name\n",
       "1626   35704_right          4              1   35704_right.jpg\n",
       "1953  97da093947e8          4              1  97da093947e8.jpg\n",
       "52      3096_right          3              0    3096_right.jpg\n",
       "834     41903_left          3              0    41903_left.jpg\n",
       "1514   28976_right          4              1   28976_right.jpg"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file_name as the index in df_data\n",
    "df_data.set_index('file_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'test_images',\n",
       " 'train_images',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/aptos2019-blindness-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['file_name'])\n",
    "\n",
    "# ============================\n",
    "# Transfer the train images\n",
    "# ============================\n",
    "\n",
    "for fname in train_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "# ============================\n",
    "# Transfer the val images\n",
    "# ============================\n",
    "\n",
    "# Get a list of train and val images\n",
    "val_list = list(df_val['file_name'])\n",
    "\n",
    "for fname in val_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954\n",
      "908\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the train sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the val sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (456, 456))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1862 images belonging to 2 classes.\n",
      "Found 207 images belonging to 2 classes.\n",
      "Found 207 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "val_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "# Get the number of train and val steps\n",
    "train_steps = np.ceil(num_train_samples // train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples // val_batch_size)\n",
    "# Pre-process the input images in the same way as the ImageNet images \n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= preprocess_image,\n",
    "    rescale=1 / 128.)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "# We are only going to use this to make a prediction on the val set. That's\n",
    "# why the path is set as val_path\n",
    "test_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=4,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in EfficientNetB5\n",
    "effnet = EfficientNetB5(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "effnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all Batch Normalization layers by Group Normalization layers\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=4, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 28,172,146\n",
      "Trainable params: 28,172,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(5, activation=sigmoid))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_0': 0, 'b_1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # Class 0\n",
    "    1: 1.0, # Class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "232/232 [==============================] - 262s 1s/step - loss: 0.6700 - categorical_accuracy: 0.5808 - val_loss: 0.6251 - val_categorical_accuracy: 0.6750\n",
      "Epoch 2/23\n",
      "232/232 [==============================] - 219s 943ms/step - loss: 0.6180 - categorical_accuracy: 0.6710 - val_loss: 0.6000 - val_categorical_accuracy: 0.6633\n",
      "Epoch 3/23\n",
      "232/232 [==============================] - 218s 938ms/step - loss: 0.5676 - categorical_accuracy: 0.7064 - val_loss: 0.5574 - val_categorical_accuracy: 0.6935\n",
      "Epoch 4/23\n",
      "232/232 [==============================] - 218s 940ms/step - loss: 0.5261 - categorical_accuracy: 0.7523 - val_loss: 0.5338 - val_categorical_accuracy: 0.7337\n",
      "Epoch 5/23\n",
      "232/232 [==============================] - 217s 935ms/step - loss: 0.5148 - categorical_accuracy: 0.7548 - val_loss: 0.5472 - val_categorical_accuracy: 0.7387\n",
      "Epoch 6/23\n",
      "232/232 [==============================] - 217s 934ms/step - loss: 0.4888 - categorical_accuracy: 0.7690 - val_loss: 0.4805 - val_categorical_accuracy: 0.7889\n",
      "Epoch 7/23\n",
      "232/232 [==============================] - 217s 937ms/step - loss: 0.4452 - categorical_accuracy: 0.8005 - val_loss: 0.5017 - val_categorical_accuracy: 0.7789\n",
      "Epoch 8/23\n",
      "232/232 [==============================] - 218s 938ms/step - loss: 0.4490 - categorical_accuracy: 0.7829 - val_loss: 0.5180 - val_categorical_accuracy: 0.7638\n",
      "Epoch 9/23\n",
      "232/232 [==============================] - 217s 935ms/step - loss: 0.4120 - categorical_accuracy: 0.8215 - val_loss: 0.4470 - val_categorical_accuracy: 0.8141\n",
      "Epoch 10/23\n",
      "232/232 [==============================] - 218s 938ms/step - loss: 0.3983 - categorical_accuracy: 0.8276 - val_loss: 0.5186 - val_categorical_accuracy: 0.7889\n",
      "Epoch 11/23\n",
      "232/232 [==============================] - 217s 935ms/step - loss: 0.3719 - categorical_accuracy: 0.8502 - val_loss: 0.4658 - val_categorical_accuracy: 0.7789\n",
      "Epoch 12/23\n",
      "232/232 [==============================] - 218s 938ms/step - loss: 0.3497 - categorical_accuracy: 0.8563 - val_loss: 0.4615 - val_categorical_accuracy: 0.8141\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 13/23\n",
      "232/232 [==============================] - 217s 937ms/step - loss: 0.3383 - categorical_accuracy: 0.8486 - val_loss: 0.5467 - val_categorical_accuracy: 0.7487\n",
      "Epoch 14/23\n",
      "232/232 [==============================] - 218s 938ms/step - loss: 0.3140 - categorical_accuracy: 0.8707 - val_loss: 0.5059 - val_categorical_accuracy: 0.8090\n",
      "Epoch 15/23\n",
      "232/232 [==============================] - 217s 937ms/step - loss: 0.2989 - categorical_accuracy: 0.8815 - val_loss: 0.5278 - val_categorical_accuracy: 0.7688\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Epoch 16/23\n",
      "232/232 [==============================] - 217s 936ms/step - loss: 0.2887 - categorical_accuracy: 0.8836 - val_loss: 0.4880 - val_categorical_accuracy: 0.7990\n",
      "Epoch 17/23\n",
      "232/232 [==============================] - 216s 933ms/step - loss: 0.2815 - categorical_accuracy: 0.8904 - val_loss: 0.4260 - val_categorical_accuracy: 0.8241\n",
      "Epoch 18/23\n",
      "232/232 [==============================] - 218s 938ms/step - loss: 0.2829 - categorical_accuracy: 0.8885 - val_loss: 0.5016 - val_categorical_accuracy: 0.7940\n",
      "Epoch 19/23\n",
      "232/232 [==============================] - 217s 936ms/step - loss: 0.2716 - categorical_accuracy: 0.8975 - val_loss: 0.5150 - val_categorical_accuracy: 0.7889\n",
      "Epoch 20/23\n",
      "232/232 [==============================] - 217s 933ms/step - loss: 0.2750 - categorical_accuracy: 0.8750 - val_loss: 0.5575 - val_categorical_accuracy: 0.7940\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 21/23\n",
      "232/232 [==============================] - 217s 934ms/step - loss: 0.2595 - categorical_accuracy: 0.9014 - val_loss: 0.5131 - val_categorical_accuracy: 0.7889\n",
      "Epoch 22/23\n",
      "232/232 [==============================] - 217s 936ms/step - loss: 0.2699 - categorical_accuracy: 0.8869 - val_loss: 0.5340 - val_categorical_accuracy: 0.7839\n",
      "Epoch 23/23\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2493 - categorical_accuracy: 0.8968"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_categorical_accuracy\", \n",
    "                      mode=\"max\", \n",
    "                      patience=12)\n",
    "\n",
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr, early_stopper, csv_logger]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_gen.samples // train_batch_size, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=23, verbose=1,\n",
    "                   callbacks=[reduce_lr, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.890507</td>\n",
       "      <td>0.281373</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.425956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  categorical_accuracy      loss        lr  val_categorical_accuracy  \\\n",
       "16     16              0.890507  0.281373  0.000003                  0.824121   \n",
       "\n",
       "    val_loss  \n",
       "16  0.425956  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training log\n",
    "df = pd.read_csv('training_log.csv')\n",
    "\n",
    "# we are monitoring val_loss\n",
    "best_acc = df['val_categorical_accuracy'].max()\n",
    "\n",
    "# display the row with the best accuracy\n",
    "df[df['val_categorical_accuracy'] == best_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.5189849413149714\n",
      "val_categorical_accuracy: 0.7968465739340403\n"
     ]
    }
   ],
   "source": [
    "# Here the best epoch will be used.\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_categorical_accuracy = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_categorical_accuracy:', val_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
