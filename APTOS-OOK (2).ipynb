{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport sys\nsys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\nfrom efficientnet import EfficientNetB5","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard dependencies\nimport cv2\nimport time\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom functools import partial\nimport matplotlib.pyplot as plt\n\n# Machine Learning\nimport tensorflow as tf\nimport keras\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras import backend as K\nfrom keras.activations import elu, relu, sigmoid, softmax\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.engine import Layer, InputSpec\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import cohen_kappa_score\n\n# Path specifications\nKAGGLE_DIR = '../input/aptos2019-blindness-detection/'\nTRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\nTEST_DF_PATH = KAGGLE_DIR + 'test.csv'\nTRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\nTEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n\n# Set seed for reproducability\nseed = 1234\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\n# For keeping time. GPU limit for this competition is set to Â± 9 hours.\nt_start = time.time()\n\n# File sizes and specifications\nprint('\\n# Files and file sizes')\nfor file in os.listdir(KAGGLE_DIR):\n    print('{}| {} MB'.format(file.ljust(30), \n                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))","execution_count":2,"outputs":[{"output_type":"stream","text":"\n# Files and file sizes\ntrain.csv                     | 0.05 MB\nsample_submission.csv         | 0.03 MB\ntest_images                   | 0.07 MB\ntrain_images                  | 0.14 MB\ntest.csv                      | 0.03 MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GroupNormalization(Layer):\n    \"\"\"Group normalization layer\n    Group Normalization divides the channels into groups and computes within each group\n    the mean and variance for normalization. GN's computation is independent of batch sizes,\n    and its accuracy is stable in a wide range of batch sizes\n    # Arguments\n        groups: Integer, the number of groups for Group Normalization.\n        axis: Integer, the axis that should be normalized\n            (typically the features axis).\n            For instance, after a `Conv2D` layer with\n            `data_format=\"channels_first\"`,\n            set `axis=1` in `BatchNormalization`.\n        epsilon: Small float added to variance to avoid dividing by zero.\n        center: If True, add offset of `beta` to normalized tensor.\n            If False, `beta` is ignored.\n        scale: If True, multiply by `gamma`.\n            If False, `gamma` is not used.\n            When the next layer is linear (also e.g. `nn.relu`),\n            this can be disabled since the scaling\n            will be done by the next layer.\n        beta_initializer: Initializer for the beta weight.\n        gamma_initializer: Initializer for the gamma weight.\n        beta_regularizer: Optional regularizer for the beta weight.\n        gamma_regularizer: Optional regularizer for the gamma weight.\n        beta_constraint: Optional constraint for the beta weight.\n        gamma_constraint: Optional constraint for the gamma weight.\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n    # Output shape\n        Same shape as input.\n    # References\n        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n    \"\"\"\n\n    def __init__(self,\n                 groups=4,\n                 axis=-1,\n                 epsilon=1e-5,\n                 center=True,\n                 scale=True,\n                 beta_initializer='zeros',\n                 gamma_initializer='ones',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(GroupNormalization, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.groups = groups\n        self.axis = axis\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n\n        if dim is None:\n            raise ValueError('Axis ' + str(self.axis) + ' of '\n                             'input tensor should have a defined dimension '\n                             'but the layer received an input with shape ' +\n                             str(input_shape) + '.')\n\n        if dim < self.groups:\n            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n                             'more than the number of channels (' +\n                             str(dim) + ').')\n\n        if dim % self.groups != 0:\n            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n                             'multiple of the number of channels (' +\n                             str(dim) + ').')\n\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name='gamma',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name='beta',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.built = True\n\n    def call(self, inputs, **kwargs):\n        input_shape = K.int_shape(inputs)\n        tensor_input_shape = K.shape(inputs)\n\n        # Prepare broadcasting shape.\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n        broadcast_shape.insert(1, self.groups)\n\n        reshape_group_shape = K.shape(inputs)\n        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n        group_axes[self.axis] = input_shape[self.axis] // self.groups\n        group_axes.insert(1, self.groups)\n\n        # reshape inputs to new group shape\n        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n        group_shape = K.stack(group_shape)\n        inputs = K.reshape(inputs, group_shape)\n\n        group_reduction_axes = list(range(len(group_axes)))\n        group_reduction_axes = group_reduction_axes[2:]\n\n        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n\n        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n\n        # prepare broadcast shape\n        inputs = K.reshape(inputs, group_shape)\n        outputs = inputs\n\n        # In this case we must explicitly broadcast all parameters.\n        if self.scale:\n            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n            outputs = outputs * broadcast_gamma\n\n        if self.center:\n            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n            outputs = outputs + broadcast_beta\n\n        outputs = K.reshape(outputs, tensor_input_shape)\n\n        return outputs\n\n    def get_config(self):\n        config = {\n            'groups': self.groups,\n            'axis': self.axis,\n            'epsilon': self.epsilon,\n            'center': self.center,\n            'scale': self.scale,\n            'beta_initializer': initializers.serialize(self.beta_initializer),\n            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n            'beta_constraint': constraints.serialize(self.beta_constraint),\n            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n        }\n        base_config = super(GroupNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify image size\nIMG_WIDTH = 456\nIMG_HEIGHT = 456\nCHANNELS = 3\n\n\n# Load in EfficientNetB5\neffnet = EfficientNetB5(weights=None,\n                        include_top=False,\n                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\neffnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace all Batch Normalization layers by Group Normalization layers\nfor i, layer in enumerate(effnet.layers):\n    if \"batch_normalization\" in layer.name:\n        effnet.layers[i] = GroupNormalization(groups=32, axis=-1, epsilon=0.00001)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    \"\"\"\n    A custom implementation of EfficientNetB5\n    for the APTOS 2019 competition\n    \n    \"\"\"\n    model = Sequential()\n    model.add(effnet)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation=\"softmax\"))\n\n    print(model.summary())\n    return model\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize model\nmodelA = build_model()\n#modelB = build_model()\n#modelC = build_model()\n#modelD = build_model()","execution_count":7,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 4098      \n=================================================================\nTotal params: 28,172,146\nTrainable params: 28,172,146\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/aptos-01')","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['__results__.html',\n '__results___files',\n '__notebook__.ipynb',\n 'effnet_modelB5.h5',\n '__output__.json',\n 'submission.csv',\n 'custom.css']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#modelA.load_weights('../input/aptos-binary-a/model.h5')\nmodelA.load_weights('../input/aptos-01a/model.h5')\n\n\n#modelB.load_weights('../input/aptos-01b/model.h5')\n\n\n#modelC.load_weights('../input/aptos-01c/model.h5')\n\n\n#modelD.load_weights('../input/aptos-01d/model.h5')\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\nTEST_DF_PATH = KAGGLE_DIR + 'test.csv'\nTEST_IMG_PATH = KAGGLE_DIR + 'test_images/'","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(TEST_DF_PATH)\n# Add extension to id_code\ntest_df['id_code'] = test_df['id_code'] + \".png\"\nprint(f\"Testing Images: {test_df.shape[0]}\")\ndisplay(test_df.head())","execution_count":11,"outputs":[{"output_type":"stream","text":"Testing Images: 1928\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            id_code\n0  0005cfc8afb6.png\n1  003f0afdcd15.png\n2  006efc72b638.png\n3  00836aaacf06.png\n4  009245722fa4.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005cfc8afb6.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>003f0afdcd15.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>006efc72b638.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00836aaacf06.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009245722fa4.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img, tol=7):\n    \"\"\"\n    Applies masks to the orignal image and \n    returns the a preprocessed image with \n    3 channels\n    \"\"\"\n    # If for some reason we only have two channels\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    # If we have a normal RGB images\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n\ndef preprocess_image(image, sigmaX=10):\n    \"\"\"\n    The whole preprocessing pipeline:\n    1. Read in image\n    2. Apply masks\n    3. Resize image to desired size\n    4. Add Gaussian noise to increase Robustness\n    \"\"\"\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n    return image","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 1\n# Place holder for diagnosis column\ntest_df['diagnosis'] = np.zeros(test_df.shape[0]) \n# For preprocessing test images\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_image, \n                                    rescale=1/ 128.).flow_from_dataframe(test_df, \n                                                                          x_col='id_code', \n                                                                          y_col='diagnosis',\n                                                                          directory=TEST_IMG_PATH,\n                                                                          target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                                          batch_size=BATCH_SIZE,\n                                                                          class_mode='other',\n                                                                          shuffle=False)","execution_count":13,"outputs":[{"output_type":"stream","text":"Found 1928 validated image filenames.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### A"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a prediction\npredictions = modelA.predict_generator(test_generator, steps=len(test_df), verbose=1)","execution_count":14,"outputs":[{"output_type":"stream","text":"1928/1928 [==============================] - 167s 87ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.shape","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(1928, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights= np.array([0.865, 1])\na=predictions*class_weights","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(a, axis=1)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['P0/P1'] = y_pred\n\ntest_df.describe()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"       diagnosis        P0/P1\ncount     1928.0  1928.000000\nmean         0.0     0.886411\nstd          0.0     0.317394\nmin          0.0     0.000000\n25%          0.0     1.000000\n50%          0.0     1.000000\n75%          0.0     1.000000\nmax          0.0     1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>P0/P1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1928.0</td>\n      <td>1928.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.0</td>\n      <td>0.886411</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.317394</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['P0/P1'].value_counts()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"1    1709\n0     219\nName: P0/P1, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1 = test_df[test_df['P0/P1']==1]\ntest_df_A0 = test_df[test_df['P0/P1']==0] #0","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(1709, 3)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor i, layer in enumerate(effnet.layers):\n    if \"batch_normalization\" in layer.name:\n        effnet.layers[i] = GroupNormalization(groups=16, axis=-1, epsilon=0.00001)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n\n    model = Sequential()\n    model.add(effnet)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(4, activation=softmax))\n\n    print(model.summary())\n    return model\n\n# Initialize model\nmodelB = build_model()","execution_count":23,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n_________________________________________________________________\nglobal_average_pooling2d_2 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 8196      \n=================================================================\nTotal params: 28,176,244\nTrainable params: 28,176,244\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelB.load_weights('../input/aptos-02b/model.h5')","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RAdam(keras.optimizers.Optimizer):\n    \"\"\"RAdam optimizer.\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Weight decay for each param.\n        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n            algorithm from the paper \"On the Convergence of Adam and\n            Beyond\".\n        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n        min_lr: float >= 0. Minimum learning rate after warmup.\n    # References\n        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n        super(RAdam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n            self.total_steps = K.variable(total_steps, name='total_steps')\n            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n            self.min_lr = K.variable(lr, name='min_lr')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.initial_weight_decay = weight_decay\n        self.initial_total_steps = total_steps\n        self.amsgrad = amsgrad\n\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        if self.initial_total_steps > 0:\n            warmup_steps = self.total_steps * self.warmup_proportion\n            decay_steps = self.total_steps - warmup_steps\n            lr = K.switch(\n                t <= warmup_steps,\n                lr * (t / warmup_steps),\n                lr * (1.0 - K.minimum(t, decay_steps) / decay_steps),\n            )\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n        else:\n            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        beta_1_t = K.pow(self.beta_1, t)\n        beta_2_t = K.pow(self.beta_2, t)\n\n        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n\n            m_corr_t = m_t / (1.0 - beta_1_t)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t) + self.epsilon)\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t) + self.epsilon)\n\n            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n                         (sma_t - 2.0) / (sma_inf - 2.0) *\n                         sma_inf / sma_t)\n\n            p_t = K.switch(sma_t > 5, r_t * m_corr_t / v_corr_t, m_corr_t)\n\n            if self.initial_weight_decay > 0:\n                p_t += self.weight_decay * p\n\n            p_t = p - lr * p_t\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {\n            'lr': float(K.get_value(self.lr)),\n            'beta_1': float(K.get_value(self.beta_1)),\n            'beta_2': float(K.get_value(self.beta_2)),\n            'decay': float(K.get_value(self.decay)),\n            'weight_decay': float(K.get_value(self.weight_decay)),\n            'epsilon': self.epsilon,\n            'amsgrad': self.amsgrad,\n            'total_steps': float(K.get_value(self.total_steps)),\n            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n            'min_lr': float(K.get_value(self.min_lr)),\n        }\n        base_config = super(RAdam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelB.compile(loss='mse',\n                  optimizer=RAdam(lr=0.00001), \n                  metrics=['mse', 'acc'])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generatorB = ImageDataGenerator(preprocessing_function=preprocess_image, \n                                    rescale=1/ 128.).flow_from_dataframe(test_df_a1, \n                                                                          x_col='id_code', \n                                                                          y_col='diagnosis',\n                                                                          directory=TEST_IMG_PATH,\n                                                                          target_size=(IMG_WIDTH, IMG_HEIGHT),\n                                                                          batch_size=BATCH_SIZE,\n                                                                          class_mode='other',\n                                                                          shuffle=False)","execution_count":27,"outputs":[{"output_type":"stream","text":"Found 1709 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a prediction\npredictions = modelB.predict_generator(test_generatorB, steps=len(test_df_a1), verbose=1)","execution_count":28,"outputs":[{"output_type":"stream","text":"1709/1709 [==============================] - 144s 84ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights= np.array([1,0.1,0.4,1.4])\nb=predictions*class_weights","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(b, axis=1)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1['P01234'] = y_pred","execution_count":31,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1['P01234'].value_counts()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"1    1255\n2     290\n0     154\n3      10\nName: P01234, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1_1 = test_df_a1[test_df_a1['P01234']==0]\ntest_df_a1_2 = test_df_a1[test_df_a1['P01234']==1]\ntest_df_a1_3 = test_df_a1[test_df_a1['P01234']==2]\ntest_df_a1_4 = test_df_a1[test_df_a1['P01234']==3]","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1_1['diagnosis'] = 1\ntest_df_a1_2['diagnosis'] = 2\ntest_df_a1_3['diagnosis'] = 3\ntest_df_a1_4['diagnosis'] = 4","execution_count":34,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_A0 = test_df_A0.iloc[:,:2]","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1 = pd.concat([test_df_a1_1, test_df_a1_2, test_df_a1_3, test_df_a1_4], axis = 0)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_a1 = test_df_a1.iloc[:,:2]","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ = pd.concat([test_df_A0, test_df_a1], axis = 0)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.shape","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"(1928, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_df['diagnosis'] = P0['Q'] + P0['Q']*P1['Q'] + P0['Q']*P1['Q']*P2['Q'] + P0['Q']*P1['Q']*P2['Q']*P4['Q']","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(TEST_DF_PATH)\n# Add extension to id_code\ntest_df['id_code'] = test_df['id_code'] + \".png\"\nprint(f\"Testing Images: {test_df.shape[0]}\")\ndisplay(test_df.head())","execution_count":40,"outputs":[{"output_type":"stream","text":"Testing Images: 1928\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"            id_code\n0  0005cfc8afb6.png\n1  003f0afdcd15.png\n2  006efc72b638.png\n3  00836aaacf06.png\n4  009245722fa4.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005cfc8afb6.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>003f0afdcd15.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>006efc72b638.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00836aaacf06.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009245722fa4.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(test_df, df_, how = 'left', on = 'id_code')","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"           id_code  diagnosis\n0     0005cfc8afb6        1.0\n1     003f0afdcd15        3.0\n2     006efc72b638        2.0\n3     00836aaacf06        2.0\n4     009245722fa4        2.0\n...            ...        ...\n1923  ff2fd94448de        0.0\n1924  ff4c945d9b17        2.0\n1925  ff64897ac0d8        2.0\n1926  ffa73465b705        2.0\n1927  ffdc2152d455        4.0\n\n[1928 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005cfc8afb6</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>003f0afdcd15</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>006efc72b638</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00836aaacf06</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009245722fa4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>009c019a7309</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>010d915e229a</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0111b949947e</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01499815e469</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0167076e7089</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>01c31b10ab99</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>01c5ba195207</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>01e4d86b3a30</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>020921b796d5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>020f6983114d</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>021c207614d6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0229c0a80d42</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>024d0a225db1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0268f4382c67</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0299d97f31f7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>03042a663e54</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>030e06ddbb04</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>033cdbbbdfaa</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>03be80919be4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>03eaa4eef484</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0434995d0654</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>04a0773c71fb</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>04e1b77ef107</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>051d9d12a6ee</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>052e00f47cfa</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1898</th>\n      <td>fc66648f758e</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1899</th>\n      <td>fc67df1e574e</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1900</th>\n      <td>fc6c9d0efe53</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1901</th>\n      <td>fc79feb5deed</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1902</th>\n      <td>fcbc1f4b5342</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1903</th>\n      <td>fcd166e6e4b5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1904</th>\n      <td>fcea00df9f33</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1905</th>\n      <td>fd2978398705</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1906</th>\n      <td>fd2d58c6cd45</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1907</th>\n      <td>fd4d81b43e84</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1908</th>\n      <td>fd7cc592106e</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1909</th>\n      <td>fd8e6b0b2e45</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1910</th>\n      <td>fda8612fcc8c</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1911</th>\n      <td>fdde61dd1bde</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1912</th>\n      <td>fde8778182af</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1913</th>\n      <td>fe0a340c4477</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1914</th>\n      <td>fe190d618acf</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1915</th>\n      <td>fe1d2f703efc</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1916</th>\n      <td>fe5618ad2460</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1917</th>\n      <td>fe57ff56618e</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1918</th>\n      <td>fe84ad1df04b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1919</th>\n      <td>fe920e47b72d</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1920</th>\n      <td>fed9d587f158</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1921</th>\n      <td>fee5bd042c3b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1922</th>\n      <td>fef8e645d030</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1923</th>\n      <td>ff2fd94448de</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1924</th>\n      <td>ff4c945d9b17</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1925</th>\n      <td>ff64897ac0d8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1926</th>\n      <td>ffa73465b705</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1927</th>\n      <td>ffdc2152d455</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1928 rows Ã 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## FINAL SUB."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove .png from ids\ndf['id_code'] = df['id_code'].str.replace(r'.png$', '')","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"           id_code  diagnosis\n0     0005cfc8afb6        1.0\n1     003f0afdcd15        3.0\n2     006efc72b638        2.0\n3     00836aaacf06        2.0\n4     009245722fa4        2.0\n...            ...        ...\n1923  ff2fd94448de        0.0\n1924  ff4c945d9b17        2.0\n1925  ff64897ac0d8        2.0\n1926  ffa73465b705        2.0\n1927  ffdc2152d455        4.0\n\n[1928 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005cfc8afb6</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>003f0afdcd15</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>006efc72b638</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00836aaacf06</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009245722fa4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>009c019a7309</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>010d915e229a</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0111b949947e</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01499815e469</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0167076e7089</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>01c31b10ab99</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>01c5ba195207</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>01e4d86b3a30</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>020921b796d5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>020f6983114d</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>021c207614d6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0229c0a80d42</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>024d0a225db1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0268f4382c67</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0299d97f31f7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>03042a663e54</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>030e06ddbb04</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>033cdbbbdfaa</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>03be80919be4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>03eaa4eef484</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0434995d0654</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>04a0773c71fb</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>04e1b77ef107</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>051d9d12a6ee</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>052e00f47cfa</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1898</th>\n      <td>fc66648f758e</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1899</th>\n      <td>fc67df1e574e</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1900</th>\n      <td>fc6c9d0efe53</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1901</th>\n      <td>fc79feb5deed</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1902</th>\n      <td>fcbc1f4b5342</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1903</th>\n      <td>fcd166e6e4b5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1904</th>\n      <td>fcea00df9f33</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1905</th>\n      <td>fd2978398705</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1906</th>\n      <td>fd2d58c6cd45</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1907</th>\n      <td>fd4d81b43e84</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1908</th>\n      <td>fd7cc592106e</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1909</th>\n      <td>fd8e6b0b2e45</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1910</th>\n      <td>fda8612fcc8c</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1911</th>\n      <td>fdde61dd1bde</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1912</th>\n      <td>fde8778182af</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1913</th>\n      <td>fe0a340c4477</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1914</th>\n      <td>fe190d618acf</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1915</th>\n      <td>fe1d2f703efc</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1916</th>\n      <td>fe5618ad2460</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1917</th>\n      <td>fe57ff56618e</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1918</th>\n      <td>fe84ad1df04b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1919</th>\n      <td>fe920e47b72d</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1920</th>\n      <td>fed9d587f158</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1921</th>\n      <td>fee5bd042c3b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1922</th>\n      <td>fef8e645d030</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1923</th>\n      <td>ff2fd94448de</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1924</th>\n      <td>ff4c945d9b17</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1925</th>\n      <td>ff64897ac0d8</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1926</th>\n      <td>ffa73465b705</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1927</th>\n      <td>ffdc2152d455</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1928 rows Ã 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#WRITE\ndf.to_csv('submission.csv', index=False)\n\nprint(\" Submission Completed;) \")","execution_count":43,"outputs":[{"output_type":"stream","text":" Submission Completed;) \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"(1928, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}