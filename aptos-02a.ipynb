{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Repository source: https://github.com/qubvel/efficientnet\n",
    "sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n",
    "from efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                        ModelCheckpoint, CSVLogger)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Files and file sizes\n",
      "test.csv                      | 0.03 MB\n",
      "test_images                   | 0.07 MB\n",
      "train.csv                     | 0.05 MB\n",
      "sample_submission.csv         | 0.03 MB\n",
      "train_images                  | 0.13 MB\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import relu, elu, hard_sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5-C.h5'\n",
    "\n",
    "# Set seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# For keeping time. GPU limit for this competition is set to Â± 9 hours.\n",
    "t_start = time.time()\n",
    "\n",
    "# File sizes and specifications\n",
    "print('\\n# Files and file sizes')\n",
    "for file in os.listdir(KAGGLE_DIR):\n",
    "    print('{}| {} MB'.format(file.ljust(30), \n",
    "                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet-keras-weights-b0b5',\n",
       " 'aptos2019-blindness-detection',\n",
       " 'diabetic-retinopathy-resized-train-15-19-dg',\n",
       " 'efficientnet',\n",
       " 'aptos-00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-A)\n",
      "Training images: 3662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              1\n",
       "3  002c21358ce6          0  002c21358ce6.png              0\n",
       "4  005b95c28852          0  005b95c28852.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-B)\n",
      "Training images: 1857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              0\n",
       "3  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "4  00a8624548a9          2  00a8624548a9.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-C)\n",
      "Training images: 1487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "      <td>00b74780d31d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              0\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "3  00a8624548a9          2  00a8624548a9.png              0\n",
       "4  00b74780d31d          2  00b74780d31d.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-D)\n",
      "Training images: 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104b032c141</td>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0243404e8a00</td>\n",
       "      <td>4</td>\n",
       "      <td>0243404e8a00.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02685f13cefd</td>\n",
       "      <td>4</td>\n",
       "      <td>02685f13cefd.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  001639a390f0          4  001639a390f0.png              1\n",
       "1  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "2  0104b032c141          3  0104b032c141.png              0\n",
       "3  0243404e8a00          4  0243404e8a00.png              1\n",
       "4  02685f13cefd          4  02685f13cefd.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path specifications\n",
    "TRAIN_DF_A_PATH = \"../input/aptos-00/df_train_A.csv\"\n",
    "TRAIN_DF_B_PATH = \"../input/aptos-00/df_train_B.csv\"\n",
    "TRAIN_DF_C_PATH = \"../input/aptos-00/df_train_C.csv\"\n",
    "TRAIN_DF_D_PATH = \"../input/aptos-00/df_train_D.csv\"\n",
    "\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-A)\")\n",
    "train_df_A = pd.read_csv(TRAIN_DF_A_PATH)\n",
    "print(f\"Training images: {train_df_A.shape[0]}\")\n",
    "display(train_df_A.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-B)\")\n",
    "train_df_B = pd.read_csv(TRAIN_DF_B_PATH)\n",
    "print(f\"Training images: {train_df_B.shape[0]}\")\n",
    "display(train_df_B.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-C)\")\n",
    "train_df_C = pd.read_csv(TRAIN_DF_C_PATH)\n",
    "print(f\"Training images: {train_df_C.shape[0]}\")\n",
    "display(train_df_C.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-D)\")\n",
    "train_df_D = pd.read_csv(TRAIN_DF_D_PATH)\n",
    "print(f\"Training images: {train_df_D.shape[0]}\")\n",
    "display(train_df_D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_A\n",
    "df0 = df.iloc[:0,:]\n",
    "df1 = df.iloc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DGTraining.csv',\n",
       " 'trainLabels15.csv',\n",
       " 'DGTesting.csv',\n",
       " 'trainLabels19.csv',\n",
       " 'testLabels15.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels15.csv')\n",
    "df_x19 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x19['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x15['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = df_x15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_x15 = df_x15[df_x15['diagnosis'] == 0]\n",
    "df_1_x15 = df_x15[df_x15['diagnosis'] == 1]\n",
    "df_2_x15 = df_x15[df_x15['diagnosis'] == 2]\n",
    "df_3_x15 = df_x15[df_x15['diagnosis'] == 3]\n",
    "df_4_x15 = df_x15[df_x15['diagnosis'] == 4]\n",
    "\n",
    "df_0_x19 = df_x19[df_x19['diagnosis'] == 0]\n",
    "df_1_x19 = df_x19[df_x19['diagnosis'] == 1]\n",
    "df_2_x19 = df_x19[df_x19['diagnosis'] == 2]\n",
    "df_3_x19 = df_x19[df_x19['diagnosis'] == 3]\n",
    "df_4_x19 = df_x19[df_x19['diagnosis'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_x15['binary_target'] = 0\n",
    "df_1_x15['binary_target'] = 1\n",
    "df_2_x15['binary_target'] = 1\n",
    "df_3_x15['binary_target'] = 1\n",
    "df_4_x15['binary_target'] = 1\n",
    "\n",
    "df_0_x19['binary_target'] = 0\n",
    "df_1_x19['binary_target'] = 1\n",
    "df_2_x19['binary_target'] = 1\n",
    "df_3_x19['binary_target'] = 1\n",
    "df_4_x19['binary_target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_0_x15,df_1_x15, df_2_x15,df_3_x15, df_4_x15, df_0_x19,df_1_x19, df_2_x19, df_3_x19, df_4_x19], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file_name column to df_train and df_test\n",
    "\n",
    "def create_fname(x):\n",
    "    \n",
    "    fname = str(x) + '.jpg'\n",
    "    \n",
    "    return fname\n",
    "\n",
    "df['file_name'] = df['id_code'].apply(create_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27615\n",
       "1    11173\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "\n",
    "df['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38788, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36660</th>\n",
       "      <td>28435_left</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28435_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30835</th>\n",
       "      <td>6240_left</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6240_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5444</th>\n",
       "      <td>9377_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9377_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20813</th>\n",
       "      <td>35925_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35925_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>3146_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3146_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code  diagnosis  binary_target       file_name\n",
       "36660  28435_left          4              1  28435_left.jpg\n",
       "30835   6240_left          2              1   6240_left.jpg\n",
       "5444   9377_right          0              0  9377_right.jpg\n",
       "20813  35925_left          0              0  35925_left.jpg\n",
       "1906   3146_right          0              0  3146_right.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df[df['binary_target'] == 1]\n",
    "df_0 = df[df['binary_target'] == 0]   #.sample(len(df_1), random_state=11)\n",
    "\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27615\n",
       "1    11173\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new target distribution\n",
    "\n",
    "df_data['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34909, 4)\n",
      "(3879, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_data, test_size=0.1, random_state=111)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24841\n",
       "1    10068\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_train['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2774\n",
       "1    1105\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_val['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create sub folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "# val_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "a_0 = os.path.join(train_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(train_dir, 'b_1')\n",
    "os.mkdir(b_1)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "a_0 = os.path.join(val_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(val_dir, 'b_1')\n",
    "os.mkdir(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_dir', 'train_dir']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the folders exist\n",
    "os.listdir('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31136</th>\n",
       "      <td>8675_right</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8675_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>13738_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13738_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>12673_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12673_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31663</th>\n",
       "      <td>12743_right</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12743_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18775</th>\n",
       "      <td>32459_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32459_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis  binary_target        file_name\n",
       "31136   8675_right          2              1   8675_right.jpg\n",
       "7931    13738_left          0              0   13738_left.jpg\n",
       "7302    12673_left          0              0   12673_left.jpg\n",
       "31663  12743_right          2              1  12743_right.jpg\n",
       "18775   32459_left          0              0   32459_left.jpg"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file_name as the index in df_data\n",
    "df_data.set_index('file_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv',\n",
       " 'test_images',\n",
       " 'train.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_images']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/aptos2019-blindness-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['file_name'])\n",
    "\n",
    "# ============================\n",
    "# Transfer the train images\n",
    "# ============================\n",
    "\n",
    "for fname in train_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "# ============================\n",
    "# Transfer the val images\n",
    "# ============================\n",
    "\n",
    "# Get a list of train and val images\n",
    "val_list = list(df_val['file_name'])\n",
    "\n",
    "for fname in val_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24841\n",
      "10068\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the train sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2774\n",
      "1105\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the val sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (456, 456))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34909 images belonging to 2 classes.\n",
      "Found 3879 images belonging to 2 classes.\n",
      "Found 3879 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "val_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "# Get the number of train and val steps\n",
    "train_steps = np.ceil(num_train_samples // train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples // val_batch_size)\n",
    "# Pre-process the input images in the same way as the ImageNet images \n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= preprocess_image,\n",
    "    rescale=1 / 128.)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "# We are only going to use this to make a prediction on the val set. That's\n",
    "# why the path is set as val_path\n",
    "test_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=4,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in EfficientNetB5\n",
    "effnet = EfficientNetB5(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "effnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all Batch Normalization layers by Group Normalization layers\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=4, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 28,172,146\n",
      "Trainable params: 28,172,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.3))\n",
    "    #model.add(Dense(5, activation=sigmoid))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_0': 0, 'b_1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # Class 0\n",
    "    1: 1.0, # Class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4363/4363 [==============================] - 4329s 992ms/step - loss: 0.4744 - categorical_accuracy: 0.7939 - val_loss: 0.3799 - val_categorical_accuracy: 0.8476\n",
      "Epoch 2/8\n",
      " 979/4363 [=====>........................] - ETA: 53:27 - loss: 0.3989 - categorical_accuracy: 0.8337"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "\n",
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr, early_stopper, csv_logger]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_gen.samples // train_batch_size, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=8, verbose=1,\n",
    "                   callbacks=[reduce_lr, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.904702</td>\n",
       "      <td>0.246856</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.882976</td>\n",
       "      <td>0.327609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  categorical_accuracy      loss       lr  val_categorical_accuracy  \\\n",
       "6      6              0.904702  0.246856  0.00001                  0.882976   \n",
       "\n",
       "   val_loss  \n",
       "6  0.327609  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training log\n",
    "df = pd.read_csv('training_log.csv')\n",
    "\n",
    "# we are monitoring val_loss\n",
    "best_acc = df['val_categorical_accuracy'].max()\n",
    "\n",
    "# display the row with the best accuracy\n",
    "df[df['val_categorical_accuracy'] == best_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3303314521136085\n",
      "val_categorical_accuracy: 0.8816438356298866\n"
     ]
    }
   ],
   "source": [
    "# Here the best epoch will be used.\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_categorical_accuracy = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_categorical_accuracy:', val_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
