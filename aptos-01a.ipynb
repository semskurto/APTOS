{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Repository source: https://github.com/qubvel/efficientnet\n",
    "sys.path.append(os.path.abspath('../input/efficientnet/efficientnet-master/efficientnet-master/'))\n",
    "from efficientnet import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n",
    "                                        ModelCheckpoint, CSVLogger)\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Files and file sizes\n",
      "sample_submission.csv         | 0.03 MB\n",
      "test_images                   | 0.07 MB\n",
      "train_images                  | 0.13 MB\n",
      "test.csv                      | 0.03 MB\n",
      "train.csv                     | 0.05 MB\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import time\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras import backend as K\n",
    "from keras.activations import relu, elu, hard_sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Path specifications\n",
    "KAGGLE_DIR = '../input/aptos2019-blindness-detection/'\n",
    "TRAIN_DF_PATH = KAGGLE_DIR + \"train.csv\"\n",
    "TEST_DF_PATH = KAGGLE_DIR + 'test.csv'\n",
    "TRAIN_IMG_PATH = KAGGLE_DIR + \"train_images/\"\n",
    "TEST_IMG_PATH = KAGGLE_DIR + 'test_images/'\n",
    "\n",
    "# Specify title of our final model\n",
    "SAVED_MODEL_NAME = 'effnet_modelB5-C.h5'\n",
    "\n",
    "# Set seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# For keeping time. GPU limit for this competition is set to Â± 9 hours.\n",
    "t_start = time.time()\n",
    "\n",
    "# File sizes and specifications\n",
    "print('\\n# Files and file sizes')\n",
    "for file in os.listdir(KAGGLE_DIR):\n",
    "    print('{}| {} MB'.format(file.ljust(30), \n",
    "                             str(round(os.path.getsize(KAGGLE_DIR + file) / 1000000, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet-keras-weights-b0b5',\n",
       " 'aptos2019-blindness-detection',\n",
       " 'diabetic-retinopathy-resized-train-15-19-dg',\n",
       " 'efficientnet',\n",
       " 'aptos-00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-A)\n",
      "Training images: 3662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              1\n",
       "3  002c21358ce6          0  002c21358ce6.png              0\n",
       "4  005b95c28852          0  005b95c28852.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-B)\n",
      "Training images: 1857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              1\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0024cdab0c1e          1  0024cdab0c1e.png              0\n",
       "3  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "4  00a8624548a9          2  00a8624548a9.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-C)\n",
      "Training images: 1487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a8624548a9</td>\n",
       "      <td>2</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b74780d31d</td>\n",
       "      <td>2</td>\n",
       "      <td>00b74780d31d.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  000c1434d8d7          2  000c1434d8d7.png              0\n",
       "1  001639a390f0          4  001639a390f0.png              1\n",
       "2  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "3  00a8624548a9          2  00a8624548a9.png              0\n",
       "4  00b74780d31d          2  00b74780d31d.png              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image IDs and Labels (TRAIN-D)\n",
      "Training images: 488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>file_name</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0083ee8054ee</td>\n",
       "      <td>4</td>\n",
       "      <td>0083ee8054ee.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104b032c141</td>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0243404e8a00</td>\n",
       "      <td>4</td>\n",
       "      <td>0243404e8a00.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02685f13cefd</td>\n",
       "      <td>4</td>\n",
       "      <td>02685f13cefd.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis         file_name  binary_target\n",
       "0  001639a390f0          4  001639a390f0.png              1\n",
       "1  0083ee8054ee          4  0083ee8054ee.png              1\n",
       "2  0104b032c141          3  0104b032c141.png              0\n",
       "3  0243404e8a00          4  0243404e8a00.png              1\n",
       "4  02685f13cefd          4  02685f13cefd.png              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path specifications\n",
    "TRAIN_DF_A_PATH = \"../input/aptos-00/df_train_A.csv\"\n",
    "TRAIN_DF_B_PATH = \"../input/aptos-00/df_train_B.csv\"\n",
    "TRAIN_DF_C_PATH = \"../input/aptos-00/df_train_C.csv\"\n",
    "TRAIN_DF_D_PATH = \"../input/aptos-00/df_train_D.csv\"\n",
    "\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-A)\")\n",
    "train_df_A = pd.read_csv(TRAIN_DF_A_PATH)\n",
    "print(f\"Training images: {train_df_A.shape[0]}\")\n",
    "display(train_df_A.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-B)\")\n",
    "train_df_B = pd.read_csv(TRAIN_DF_B_PATH)\n",
    "print(f\"Training images: {train_df_B.shape[0]}\")\n",
    "display(train_df_B.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-C)\")\n",
    "train_df_C = pd.read_csv(TRAIN_DF_C_PATH)\n",
    "print(f\"Training images: {train_df_C.shape[0]}\")\n",
    "display(train_df_C.head())\n",
    "\n",
    "print(\"Image IDs and Labels (TRAIN-D)\")\n",
    "train_df_D = pd.read_csv(TRAIN_DF_D_PATH)\n",
    "print(f\"Training images: {train_df_D.shape[0]}\")\n",
    "display(train_df_D.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_A\n",
    "df0 = df.iloc[:0,:]\n",
    "df1 = df.iloc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DGTraining.csv',\n",
       " 'trainLabels19.csv',\n",
       " 'DGTesting.csv',\n",
       " 'testLabels15.csv',\n",
       " 'trainLabels15.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels15.csv')\n",
    "df_x19 = pd.read_csv('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/trainlabels/trainLabels19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x19['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25810\n",
       "2     5292\n",
       "1     2443\n",
       "3      873\n",
       "4      708\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x15['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x15 = df_x15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_x15 = df_x15[df_x15['diagnosis'] == 0]\n",
    "df_1_x15 = df_x15[df_x15['diagnosis'] == 1]\n",
    "df_2_x15 = df_x15[df_x15['diagnosis'] == 2]\n",
    "df_3_x15 = df_x15[df_x15['diagnosis'] == 3]\n",
    "df_4_x15 = df_x15[df_x15['diagnosis'] == 4]\n",
    "\n",
    "df_0_x19 = df_x19[df_x19['diagnosis'] == 0]\n",
    "df_1_x19 = df_x19[df_x19['diagnosis'] == 1]\n",
    "df_2_x19 = df_x19[df_x19['diagnosis'] == 2]\n",
    "df_3_x19 = df_x19[df_x19['diagnosis'] == 3]\n",
    "df_4_x19 = df_x19[df_x19['diagnosis'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_x15['binary_target'] = 0\n",
    "df_1_x15['binary_target'] = 1\n",
    "df_2_x15['binary_target'] = 1\n",
    "df_3_x15['binary_target'] = 1\n",
    "df_4_x15['binary_target'] = 1\n",
    "\n",
    "df_0_x19['binary_target'] = 0\n",
    "df_1_x19['binary_target'] = 1\n",
    "df_2_x19['binary_target'] = 1\n",
    "df_3_x19['binary_target'] = 1\n",
    "df_4_x19['binary_target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_0_x15,df_1_x15, df_2_x15,df_3_x15, df_4_x15, df_0_x19,df_1_x19, df_2_x19, df_3_x19, df_4_x19], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file_name column to df_train and df_test\n",
    "\n",
    "def create_fname(x):\n",
    "    \n",
    "    fname = str(x) + '.jpg'\n",
    "    \n",
    "    return fname\n",
    "\n",
    "df['file_name'] = df['id_code'].apply(create_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27615\n",
       "1    11173\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target distribution\n",
    "\n",
    "df['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22346, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>27379_left</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27379_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>3623_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3623_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>22535_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22535_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>39052_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39052_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>25959_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25959_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis  binary_target        file_name\n",
       "16957   27379_left          2              1   27379_left.jpg\n",
       "10677   3623_right          0              0   3623_right.jpg\n",
       "4732   22535_right          0              0  22535_right.jpg\n",
       "494    39052_right          0              0  39052_right.jpg\n",
       "860     25959_left          0              0   25959_left.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df[df['binary_target'] == 1]\n",
    "df_0 = df[df['binary_target'] == 0].sample(len(df_1), random_state=11)\n",
    "\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11173\n",
       "0    11173\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new target distribution\n",
    "\n",
    "df_data['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20111, 4)\n",
      "(2235, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_data, test_size=0.1, random_state=11)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10070\n",
       "1    10041\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_train['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1132\n",
       "0    1103\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train set target distribution\n",
    "df_val['binary_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create sub folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "# val_dir\n",
    "    # a_0\n",
    "    # b_1\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "a_0 = os.path.join(train_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(train_dir, 'b_1')\n",
    "os.mkdir(b_1)\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "a_0 = os.path.join(val_dir, 'a_0')\n",
    "os.mkdir(a_0)\n",
    "b_1 = os.path.join(val_dir, 'b_1')\n",
    "os.mkdir(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_dir', 'train_dir']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the folders exist\n",
    "os.listdir('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>37790_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37790_left.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11435</th>\n",
       "      <td>4946_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4946_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12234</th>\n",
       "      <td>18392_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18392_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>43584_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43584_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>27833_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27833_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis  binary_target        file_name\n",
       "8256    37790_left          0              0   37790_left.jpg\n",
       "11435   4946_right          1              1   4946_right.jpg\n",
       "12234  18392_right          1              1  18392_right.jpg\n",
       "6598   43584_right          0              0  43584_right.jpg\n",
       "3962   27833_right          0              0  27833_right.jpg"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file_name as the index in df_data\n",
    "df_data.set_index('file_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image size\n",
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'test_images',\n",
       " 'train_images',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/aptos2019-blindness-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['file_name'])\n",
    "\n",
    "# ============================\n",
    "# Transfer the train images\n",
    "# ============================\n",
    "\n",
    "for fname in train_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        # save the image at the destination\n",
    "        # save the image using PIL\n",
    "        #result = Image.fromarray(image.astype(np.uint8))\n",
    "        #result.save(dst)\n",
    "        # copy the image from the source to the destination\n",
    "        #shutil.copyfile(src, dst)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "# ============================\n",
    "# Transfer the val images\n",
    "# ============================\n",
    "\n",
    "# Get a list of train and val images\n",
    "val_list = list(df_val['file_name'])\n",
    "\n",
    "for fname in val_list:\n",
    "    \n",
    "    label = df_data.loc[fname,'binary_target']\n",
    "    \n",
    "    if label == 0:\n",
    "        sub_folder = 'a_0'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)\n",
    "        \n",
    "        \n",
    "    if label == 1:\n",
    "        sub_folder = 'b_1'\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/diabetic-retinopathy-resized-train-15-19-dg/resized_train_15_19_dg/resized_train_15_19_DG', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, sub_folder, fname)\n",
    "        \n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (456, 456))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10070\n",
      "10041\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the train sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n",
      "1132\n"
     ]
    }
   ],
   "source": [
    "# Check how many images are in the val sub folders\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/a_0')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Applies masks to the orignal image and \n",
    "    returns the a preprocessed image with \n",
    "    3 channels\n",
    "    \"\"\"\n",
    "    # If for some reason we only have two channels\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    # If we have a normal RGB images\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (456, 456))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 456\n",
    "IMG_HEIGHT = 456\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20111 images belonging to 2 classes.\n",
      "Found 2235 images belonging to 2 classes.\n",
      "Found 2235 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "val_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "# Get the number of train and val steps\n",
    "train_steps = np.ceil(num_train_samples // train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples // val_batch_size)\n",
    "# Pre-process the input images in the same way as the ImageNet images \n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= preprocess_image,\n",
    "    rescale=1 / 128.)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "# We are only going to use this to make a prediction on the val set. That's\n",
    "# why the path is set as val_path\n",
    "test_gen = datagen.flow_from_directory(val_path,\n",
    "                                            target_size=(456,456),\n",
    "                                            batch_size=val_batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "    \"\"\"Group normalization layer\n",
    "    Group Normalization divides the channels into groups and computes within each group\n",
    "    the mean and variance for normalization. GN's computation is independent of batch sizes,\n",
    "    and its accuracy is stable in a wide range of batch sizes\n",
    "    # Arguments\n",
    "        groups: Integer, the number of groups for Group Normalization.\n",
    "        axis: Integer, the axis that should be normalized\n",
    "            (typically the features axis).\n",
    "            For instance, after a `Conv2D` layer with\n",
    "            `data_format=\"channels_first\"`,\n",
    "            set `axis=1` in `BatchNormalization`.\n",
    "        epsilon: Small float added to variance to avoid dividing by zero.\n",
    "        center: If True, add offset of `beta` to normalized tensor.\n",
    "            If False, `beta` is ignored.\n",
    "        scale: If True, multiply by `gamma`.\n",
    "            If False, `gamma` is not used.\n",
    "            When the next layer is linear (also e.g. `nn.relu`),\n",
    "            this can be disabled since the scaling\n",
    "            will be done by the next layer.\n",
    "        beta_initializer: Initializer for the beta weight.\n",
    "        gamma_initializer: Initializer for the gamma weight.\n",
    "        beta_regularizer: Optional regularizer for the beta weight.\n",
    "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        beta_constraint: Optional constraint for the beta weight.\n",
    "        gamma_constraint: Optional constraint for the gamma weight.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as input.\n",
    "    # References\n",
    "        - [Group Normalization](https://arxiv.org/abs/1803.08494)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 groups=4,\n",
    "                 axis=-1,\n",
    "                 epsilon=1e-5,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(GroupNormalization, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.groups = groups\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "\n",
    "        if dim < self.groups:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') cannot be '\n",
    "                             'more than the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        if dim % self.groups != 0:\n",
    "            raise ValueError('Number of groups (' + str(self.groups) + ') must be a '\n",
    "                             'multiple of the number of channels (' +\n",
    "                             str(dim) + ').')\n",
    "\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        tensor_input_shape = K.shape(inputs)\n",
    "\n",
    "        # Prepare broadcasting shape.\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "        broadcast_shape.insert(1, self.groups)\n",
    "\n",
    "        reshape_group_shape = K.shape(inputs)\n",
    "        group_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "        group_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "        group_axes.insert(1, self.groups)\n",
    "\n",
    "        # reshape inputs to new group shape\n",
    "        group_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "        group_shape = K.stack(group_shape)\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "        group_reduction_axes = list(range(len(group_axes)))\n",
    "        group_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "        mean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "        variance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\n",
    "        inputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "        # prepare broadcast shape\n",
    "        inputs = K.reshape(inputs, group_shape)\n",
    "        outputs = inputs\n",
    "\n",
    "        # In this case we must explicitly broadcast all parameters.\n",
    "        if self.scale:\n",
    "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "            outputs = outputs * broadcast_gamma\n",
    "\n",
    "        if self.center:\n",
    "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "            outputs = outputs + broadcast_beta\n",
    "\n",
    "        outputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'groups': self.groups,\n",
    "            'axis': self.axis,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(GroupNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in EfficientNetB5\n",
    "effnet = EfficientNetB5(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
    "effnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all Batch Normalization layers by Group Normalization layers\n",
    "for i, layer in enumerate(effnet.layers):\n",
    "    if \"batch_normalization\" in layer.name:\n",
    "        effnet.layers[i] = GroupNormalization(groups=4, axis=-1, epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 15, 15, 2048)      28168048  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 28,172,146\n",
      "Trainable params: 28,172,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(effnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(5, activation=sigmoid))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a_0': 0, 'b_1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # Class 0\n",
    "    1: 1.0, # Class 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "2513/2513 [==============================] - 2393s 952ms/step - loss: 0.5807 - categorical_accuracy: 0.6806 - val_loss: 0.5022 - val_categorical_accuracy: 0.7536\n",
      "Epoch 2/7\n",
      "2513/2513 [==============================] - 2352s 936ms/step - loss: 0.4982 - categorical_accuracy: 0.7521 - val_loss: 0.4414 - val_categorical_accuracy: 0.7943\n",
      "Epoch 3/7\n",
      " 317/2513 [==>...........................] - ETA: 33:07 - loss: 0.4737 - categorical_accuracy: 0.7670"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_categorical_accuracy\", \n",
    "                      mode=\"max\", \n",
    "                      patience=12)\n",
    "\n",
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=False)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr, early_stopper, csv_logger]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_gen.samples // train_batch_size, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=7, verbose=1,\n",
    "                   callbacks=[reduce_lr, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.846093</td>\n",
       "      <td>0.348418</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.828469</td>\n",
       "      <td>0.386865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  categorical_accuracy      loss       lr  val_categorical_accuracy  \\\n",
       "6      6              0.846093  0.348418  0.00001                  0.828469   \n",
       "\n",
       "   val_loss  \n",
       "6  0.386865  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training log\n",
    "df = pd.read_csv('training_log.csv')\n",
    "\n",
    "# we are monitoring val_loss\n",
    "best_acc = df['val_categorical_accuracy'].max()\n",
    "\n",
    "# display the row with the best accuracy\n",
    "df[df['val_categorical_accuracy'] == best_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39012934087006373\n",
      "val_categorical_accuracy: 0.8278509386382741\n"
     ]
    }
   ],
   "source": [
    "# Here the best epoch will be used.\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_categorical_accuracy = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_categorical_accuracy:', val_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
